#!/usr/bin/env python3
"""
Performance Analysis Module
ì„±ëŠ¥ ë¶„ì„ ëª¨ë“ˆ - íŒŒì´í”„ë¼ì¸ ê° ë‹¨ê³„ë³„ ì„±ëŠ¥ ì¸¡ì • ë° bottleneck ë¶„ì„
"""

import time
import numpy as np
from typing import Dict, List, Tuple, Optional
import logging
from pathlib import Path
import json
from dataclasses import dataclass
from collections import defaultdict

logger = logging.getLogger(__name__)

@dataclass
class StageMetrics:
    """ë‹¨ê³„ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    stage_name: str
    total_time: float
    frame_count: int
    fps: float
    memory_peak: Optional[float] = None
    
    def to_dict(self) -> Dict:
        return {
            'stage_name': self.stage_name,
            'total_time': self.total_time,
            'frame_count': self.frame_count,
            'fps': self.fps,
            'memory_peak': self.memory_peak
        }

class PerformanceAnalyzer:
    """
    ì„±ëŠ¥ ë¶„ì„ê¸° - íŒŒì´í”„ë¼ì¸ ê° ë‹¨ê³„ë³„ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
    """
    
    def __init__(self):
        self.stage_times = defaultdict(list)
        self.current_stage = None
        self.stage_start_time = None
        self.total_frames = 0
        self.memory_tracker = {}
        
    def start_stage(self, stage_name: str):
        """ë‹¨ê³„ ì‹œì‘"""
        if self.current_stage is not None:
            logger.warning(f"ì´ì „ ë‹¨ê³„ {self.current_stage}ê°€ ì™„ë£Œë˜ì§€ ì•ŠìŒ")
            
        self.current_stage = stage_name
        self.stage_start_time = time.time()
        
        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì  (ê°€ëŠ¥í•œ ê²½ìš°)
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.synchronize()
                self.memory_tracker[stage_name + '_start'] = torch.cuda.memory_allocated() / 1024**2  # MB
        except Exception:
            pass
    
    def end_stage(self) -> float:
        """ë‹¨ê³„ ì¢…ë£Œ ë° ì‹œê°„ ë°˜í™˜"""
        if self.current_stage is None or self.stage_start_time is None:
            logger.warning("ì‹œì‘ë˜ì§€ ì•Šì€ ë‹¨ê³„ë¥¼ ì¢…ë£Œí•˜ë ¤ê³  í•¨")
            return 0.0
            
        elapsed_time = time.time() - self.stage_start_time
        self.stage_times[self.current_stage].append(elapsed_time)
        
        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì  (ê°€ëŠ¥í•œ ê²½ìš°)
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.synchronize()
                self.memory_tracker[self.current_stage + '_end'] = torch.cuda.memory_allocated() / 1024**2  # MB
        except Exception:
            pass
        
        logger.info(f"{self.current_stage} ì™„ë£Œ: {elapsed_time:.3f}ì´ˆ")
        
        stage_name = self.current_stage
        self.current_stage = None
        self.stage_start_time = None
        
        return elapsed_time
    
    def get_stage_metrics(self, stage_name: str, frame_count: Optional[int] = None) -> StageMetrics:
        """ë‹¨ê³„ë³„ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        times = self.stage_times.get(stage_name, [])
        if not times:
            return StageMetrics(stage_name, 0.0, 0, 0.0)
            
        total_time = sum(times)
        avg_time = total_time / len(times)
        
        if frame_count is None:
            frame_count = self.total_frames
            
        fps = frame_count / total_time if total_time > 0 else 0.0
        
        # ë©”ëª¨ë¦¬ í”¼í¬ ê³„ì‚°
        memory_peak = None
        start_mem = self.memory_tracker.get(stage_name + '_start')
        end_mem = self.memory_tracker.get(stage_name + '_end')
        if start_mem is not None and end_mem is not None:
            memory_peak = max(start_mem, end_mem)
        
        return StageMetrics(stage_name, total_time, frame_count, fps, memory_peak)
    
    def analyze_performance(self, total_frames: int) -> Dict:
        """ì „ì²´ ì„±ëŠ¥ ë¶„ì„"""
        self.total_frames = total_frames
        
        analysis = {
            'total_frames': total_frames,
            'stages': {},
            'bottlenecks': [],
            'recommendations': []
        }
        
        # ê° ë‹¨ê³„ë³„ ë©”íŠ¸ë¦­ ê³„ì‚°
        stage_metrics = {}
        for stage_name in self.stage_times.keys():
            metrics = self.get_stage_metrics(stage_name, total_frames)
            stage_metrics[stage_name] = metrics
            analysis['stages'][stage_name] = metrics.to_dict()
        
        # Bottleneck ë¶„ì„
        if stage_metrics:
            # ê°€ì¥ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ë‹¨ê³„ë“¤
            sorted_stages = sorted(stage_metrics.values(), key=lambda x: x.total_time, reverse=True)
            total_time = sum(m.total_time for m in stage_metrics.values())
            
            for metrics in sorted_stages[:3]:  # ìƒìœ„ 3ê°œ ë‹¨ê³„
                percentage = (metrics.total_time / total_time) * 100 if total_time > 0 else 0
                if percentage > 20:  # 20% ì´ìƒì´ë©´ bottleneck
                    analysis['bottlenecks'].append({
                        'stage': metrics.stage_name,
                        'time': metrics.total_time,
                        'percentage': percentage,
                        'fps': metrics.fps
                    })
        
        # ìµœì í™” ê¶Œì¥ì‚¬í•­
        analysis['recommendations'] = self._generate_recommendations(stage_metrics, total_frames)
        
        return analysis
    
    def _generate_recommendations(self, stage_metrics: Dict[str, StageMetrics], total_frames: int) -> List[str]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if not stage_metrics:
            return recommendations
        
        # ì „ì²´ FPS ê³„ì‚°
        total_time = sum(m.total_time for m in stage_metrics.values())
        overall_fps = total_frames / total_time if total_time > 0 else 0
        
        if overall_fps < 15:  # 15fps ë¯¸ë§Œì´ë©´ ì„±ëŠ¥ ê°œì„  í•„ìš”
            recommendations.append(f"ì „ì²´ FPS {overall_fps:.1f}fpsë¡œ ì„±ëŠ¥ ê°œì„  í•„ìš” (ëª©í‘œ: 20-30fps)")
        
        # ë‹¨ê³„ë³„ ë¶„ì„ ë° ê¶Œì¥ì‚¬í•­
        for stage_name, metrics in stage_metrics.items():
            if 'pose_estimation' in stage_name.lower():
                if metrics.fps < 20:
                    recommendations.append("í¬ì¦ˆ ì¶”ì • ìµœì í™”: ë°°ì¹˜ ì²˜ë¦¬, í•´ìƒë„ ì¡°ì •, ëª¨ë¸ ìµœì í™” ê³ ë ¤")
                    
            elif 'tracking' in stage_name.lower():
                if metrics.fps < 50:
                    recommendations.append("íŠ¸ë˜í‚¹ ìµœì í™”: ByteTrack ì„¤ì • ì¡°ì •, detection threshold ìµœì í™”")
                    
            elif 'classification' in stage_name.lower():
                if metrics.fps < 100:
                    recommendations.append("ë¶„ë¥˜ ìµœì í™”: ë°°ì¹˜ í¬ê¸° ì¦ê°€, ì‹œí€€ìŠ¤ ê¸¸ì´ ì¡°ì • ê³ ë ¤")
                    
            elif 'overlay' in stage_name.lower():
                if metrics.fps < 30:
                    recommendations.append("ì˜¤ë²„ë ˆì´ ìµœì í™”: OpenCV ìµœì í™”, MMPose ì‹œê°í™” ì„¤ì • ì¡°ì •")
        
        return recommendations
    
    def save_analysis(self, analysis: Dict, output_path: str):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, indent=2, ensure_ascii=False)
        logger.info(f"ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_path}")
    
    def print_summary(self, analysis: Dict):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸš€ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼")
        print("="*60)
        
        total_frames = analysis['total_frames']
        print(f"ğŸ“¹ ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
        
        print("\nğŸ“Š ë‹¨ê³„ë³„ ì„±ëŠ¥:")
        for stage_name, metrics in analysis['stages'].items():
            print(f"  â€¢ {stage_name}:")
            print(f"    - ì²˜ë¦¬ ì‹œê°„: {metrics['total_time']:.2f}ì´ˆ")
            print(f"    - FPS: {metrics['fps']:.1f}")
            if metrics['memory_peak']:
                print(f"    - ë©”ëª¨ë¦¬ í”¼í¬: {metrics['memory_peak']:.1f}MB")
        
        # ì „ì²´ FPS ê³„ì‚°
        total_time = sum(m['total_time'] for m in analysis['stages'].values())
        overall_fps = total_frames / total_time if total_time > 0 else 0
        print(f"\nğŸ¯ ì „ì²´ ì„±ëŠ¥: {overall_fps:.1f} FPS ({total_time:.2f}ì´ˆ)")
        
        if analysis['bottlenecks']:
            print(f"\nğŸ”´ Bottleneck ë‹¨ê³„:")
            for bottleneck in analysis['bottlenecks']:
                print(f"  â€¢ {bottleneck['stage']}: {bottleneck['percentage']:.1f}% ({bottleneck['time']:.2f}ì´ˆ)")
        
        if analysis['recommendations']:
            print(f"\nğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­:")
            for i, rec in enumerate(analysis['recommendations'], 1):
                print(f"  {i}. {rec}")
        
        print("="*60)

# Context manager for easy stage timing
class StageTimer:
    """ë‹¨ê³„ë³„ ì‹œê°„ ì¸¡ì •ìš© ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    
    def __init__(self, analyzer: PerformanceAnalyzer, stage_name: str):
        self.analyzer = analyzer
        self.stage_name = stage_name
    
    def __enter__(self):
        self.analyzer.start_stage(self.stage_name)
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.analyzer.end_stage()