#!/usr/bin/env python3
"""
Resolution Optimization Test
í•´ìƒë„ ìµœì í™” í…ŒìŠ¤íŠ¸ - ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ì„±ëŠ¥ ê°œì„ 
"""

import os
import sys
import time
import cv2
import numpy as np

sys.path.append('/workspace/rtmo_gcn_pipeline/inference_pipeline')

from pose_estimator import RTMOPoseEstimator
from config import POSE_CONFIG, POSE_CHECKPOINT

def test_resolution_impact():
    """í•´ìƒë„ë³„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ¯ í•´ìƒë„ë³„ RTMO ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    
    # í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤
    video_path = "/aivanas/raw/surveillance/action/violence/action_recognition/data/UCF_Crime_test/Fight/Fighting033_x264.mp4"
    max_test_frames = 50  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 50í”„ë ˆì„ë§Œ
    
    # RTMO ì¶”ì •ê¸° ì´ˆê¸°í™”
    estimator = RTMOPoseEstimator(POSE_CONFIG, POSE_CHECKPOINT, 'cuda:0')
    
    # í•´ìƒë„ í…ŒìŠ¤íŠ¸ ì„¤ì •
    resolution_tests = [
        {'scale': 1.0, 'name': 'ì›ë³¸ (100%)', 'target_size': None},
        {'scale': 0.8, 'name': 'ê³ í’ˆì§ˆ (80%)', 'target_size': (512, 384)},
        {'scale': 0.6, 'name': 'ê· í˜• (60%)', 'target_size': (384, 288)},
        {'scale': 0.4, 'name': 'ê³ ì† (40%)', 'target_size': (256, 192)},
    ]
    
    results = []
    
    for test_config in resolution_tests:
        print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸: {test_config['name']}")
        
        # ë¹„ë””ì˜¤ ì—´ê¸°
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
            continue
        
        frames = []
        for i in range(max_test_frames):
            ret, frame = cap.read()
            if not ret:
                break
                
            # í•´ìƒë„ ì¡°ì •
            if test_config['target_size']:
                frame = cv2.resize(frame, test_config['target_size'])
            
            frames.append(frame)
        
        cap.release()
        
        if not frames:
            print("âŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
            continue
        
        print(f"   í”„ë ˆì„ ìˆ˜: {len(frames)}")
        print(f"   í•´ìƒë„: {frames[0].shape[1]}x{frames[0].shape[0]}")
        
        # ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        
        pose_results = []
        for frame in frames:
            try:
                # RTMO ì¶”ë¡ 
                from mmpose.apis import inference_bottomup
                result = inference_bottomup(estimator.model, frame)
                
                if result and len(result.pred_instances) > 0:
                    keypoints = result.pred_instances.keypoints.cpu().numpy()
                    scores = result.pred_instances.keypoint_scores.cpu().numpy()
                    pose_results.append((keypoints, scores))
                else:
                    pose_results.append((np.empty((0, 17, 2)), np.empty((0, 17))))
                    
            except Exception as e:
                print(f"   âš ï¸  í”„ë ˆì„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                pose_results.append((np.empty((0, 17, 2)), np.empty((0, 17))))
        
        processing_time = time.time() - start_time
        fps = len(frames) / processing_time if processing_time > 0 else 0
        
        # ê²°ê³¼ ì €ì¥
        test_result = {
            'name': test_config['name'],
            'scale': test_config['scale'],
            'frames': len(frames),
            'time': processing_time,
            'fps': fps,
            'valid_poses': sum(1 for kpts, scores in pose_results if len(kpts) > 0)
        }
        results.append(test_result)
        
        print(f"   ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        print(f"   FPS: {fps:.1f}")
        print(f"   ìœ íš¨ í¬ì¦ˆ: {test_result['valid_poses']}/{len(frames)}")
    
    # ê²°ê³¼ ë¹„êµ
    print(f"\nğŸš€ í•´ìƒë„ë³„ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
    print("-" * 60)
    print(f"{'í•´ìƒë„':<12} {'FPS':<8} {'ì²˜ë¦¬ì‹œê°„':<10} {'ì„±ëŠ¥í–¥ìƒ':<10} {'ì •í™•ë„':<8}")
    print("-" * 60)
    
    baseline_fps = results[0]['fps'] if results else 1
    
    for result in results:
        speedup = result['fps'] / baseline_fps if baseline_fps > 0 else 0
        accuracy = (result['valid_poses'] / result['frames']) * 100 if result['frames'] > 0 else 0
        
        print(f"{result['name']:<12} {result['fps']:<8.1f} {result['time']:<10.2f} "
              f"{speedup:<10.1f}x {accuracy:<8.1f}%")
    
    # ê¶Œì¥ì‚¬í•­
    print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
    
    if len(results) >= 2:
        best_balance = max(results[1:], key=lambda x: x['fps'] * (x['valid_poses']/x['frames']))
        print(f"   ìµœì  ì„¤ì •: {best_balance['name']}")
        print(f"   ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: {(best_balance['fps']/baseline_fps):.1f}ë°°")
        print(f"   ì‹¤ì œ íŒŒì´í”„ë¼ì¸ ì ìš© ì‹œ:")
        print(f"   í˜„ì¬ 10.3 FPS â†’ ì˜ˆìƒ {10.3 * (best_balance['fps']/baseline_fps):.1f} FPS")
    
    return results

if __name__ == "__main__":
    test_resolution_impact()