"""
STGCN++ í–¥ìƒëœ ë°ì´í„° ì¦ê°• ì„¤ì •
Dense training data (stride=10) + ì ê·¹ì ì¸ ë°ì´í„° ì¦ê°• ì ìš©
"""

# model settings
model = dict(
    type='RecognizerGCN',
    backbone=dict(
        type='STGCN',
        gcn_adaptive=True,
        gcn_with_res=True,
        tcn_type='mstcn',
        graph_cfg=dict(layout='coco', strategy='spatial')),
    cls_head=dict(type='GCNHead', num_classes=2, in_channels=256))

# dataset settings
dataset_type = 'PoseDataset'
ann_file_train = '/workspace/rtmo_gcn_pipeline/rtmo_pose_track/output/dense_training/rwf2000_enhanced_sliding_train.pkl'
ann_file_val = '/workspace/rtmo_gcn_pipeline/rtmo_pose_track/output/dense_training/rwf2000_enhanced_sliding_val.pkl'
ann_file_test = '/workspace/rtmo_gcn_pipeline/rtmo_pose_track/output/sparse_inference/rwf2000_enhanced_sliding_test.pkl'

left_kp = [1, 3, 5, 7, 9, 11, 13, 15]
right_kp = [2, 4, 6, 8, 10, 12, 14, 16]

# ğŸš€ í–¥ìƒëœ í•™ìŠµìš© ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸
train_pipeline = [
    dict(type='PreNormalize2D'),
    dict(type='GenSkeFeat', dataset='coco'),
    
    # 1. ì¢Œìš° ë°˜ì „ (ê°€ì¥ ê¸°ë³¸ì ì´ê³  íš¨ê³¼ì )
    dict(type='RandomFlip', 
         flip_ratio=0.5,
         left_kp=left_kp, 
         right_kp=right_kp),
    
    # 2. íšŒì „ ë³€í˜• (ìì—°ìŠ¤ëŸ¬ìš´ ì‹œì  ë³€í™”)
    dict(type='RandomRot',
         rot_range=[-15, 15],  # Â±15ë„ íšŒì „
         prob=0.4),
    
    # 3. í¬ê¸° ì¡°ì ˆ (ë‹¤ì–‘í•œ ê±°ë¦¬ê°)
    dict(type='RandomScale',
         scale_range=[0.85, 1.15],  # 85%-115% í¬ê¸° ë³€í™”
         prob=0.5),
    
    # 4. ì „ë‹¨ ë³€í˜• (ì¹´ë©”ë¼ ê°ë„ ë³€í™” ì‹œë®¬ë ˆì´ì…˜)
    dict(type='RandomShear',
         shear_range=[-10, 10],  # Â±10ë„ ì „ë‹¨
         prob=0.3),
    
    # 5. ë…¸ì´ì¦ˆ ì¶”ê°€ (ì„¼ì„œ ë…¸ì´ì¦ˆ, ê°€ë ¤ì§ ì‹œë®¬ë ˆì´ì…˜)
    dict(type='RandomJitter',
         noise_std=0.05,  # í‚¤í¬ì¸íŠ¸ ìœ„ì¹˜ì— ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ
         prob=0.4),
    
    # 6. í‚¤í¬ì¸íŠ¸ ê°€ë ¤ì§ (ì¼ë¶€ ê´€ì ˆì´ ë³´ì´ì§€ ì•ŠëŠ” ìƒí™©)
    dict(type='RandomOcclusion',
         occlusion_ratio=0.1,  # 10% í‚¤í¬ì¸íŠ¸ ê°€ë ¤ì§
         prob=0.3),
    
    # 7. ì‹œê°„ì  ì¼ê´€ì„± ë³€í˜• (í”„ë ˆì„ ìˆœì„œ ì•½ê°„ ë³€ê²½)
    dict(type='RandomTemporalSubSample',
         temporal_jitter_ratio=0.05,  # 5% ì‹œê°„ì  ë³€ë™
         prob=0.2),
    
    dict(type='FormatGCNInput', num_person=2),
    dict(type='Collect', keys=['keypoint', 'label'], meta_keys=[]),
    dict(type='ToTensor', keys=['keypoint'])
]

# ğŸ¯ ê²€ì¦/ì¶”ë¡ ìš© íŒŒì´í”„ë¼ì¸ (ì¦ê°• ì—†ìŒ)
val_pipeline = [
    dict(type='PreNormalize2D'),
    dict(type='GenSkeFeat', dataset='coco'),
    dict(type='FormatGCNInput', num_person=2),
    dict(type='Collect', keys=['keypoint', 'label'], meta_keys=[]),
    dict(type='ToTensor', keys=['keypoint'])
]

test_pipeline = [
    dict(type='PreNormalize2D'),
    dict(type='GenSkeFeat', dataset='coco'),
    dict(type='FormatGCNInput', num_person=2),
    dict(type='Collect', keys=['keypoint', 'label'], meta_keys=[]),
    dict(type='ToTensor', keys=['keypoint'])
]

data = dict(
    videos_per_gpu=32,  # ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •)
    workers_per_gpu=4,
    test_dataloader=dict(videos_per_gpu=1),
    
    train=dict(
        type=dataset_type,
        ann_file=ann_file_train,
        data_prefix='',
        pipeline=train_pipeline),  # ì¦ê°• íŒŒì´í”„ë¼ì¸ ì ìš©
    
    val=dict(
        type=dataset_type,
        ann_file=ann_file_val,
        data_prefix='',
        pipeline=val_pipeline),   # ì¦ê°• ì—†ìŒ
    
    test=dict(
        type=dataset_type,
        ann_file=ann_file_test,
        data_prefix='',
        pipeline=test_pipeline))  # ì¶”ë¡ ìš© sparse ë°ì´í„° + ì¦ê°• ì—†ìŒ

# optimizer
optimizer = dict(
    type='AdamW', 
    lr=0.001,         # ë‚®ì€ í•™ìŠµë¥  (AdamWì— ì í•©)
    weight_decay=0.01,
    betas=(0.9, 0.999))

optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))

# learning policy
lr_config = dict(
    policy='CosineAnnealing',
    min_lr=0.0001,    # ìµœì†Œ í•™ìŠµë¥ ë„ ë‚®ê²Œ ì¡°ì •
    warmup='linear',
    warmup_iters=1000,     # ë” ê¸´ ì›Œë°ì—… (AdamWì— ìœ ë¦¬)
    warmup_ratio=0.1)

total_epochs = 80          # ì—í­ ìˆ˜ (ë” ë§ì€ ë°ì´í„°ë¡œ ë” ì˜¤ë˜ í•™ìŠµ)

checkpoint_config = dict(interval=5)
evaluation = dict(
    interval=5, 
    metrics=['top_k_accuracy', 'mean_class_accuracy'],
    topk=(1, 2))

log_config = dict(
    interval=50,           # ë¡œê·¸ ì¶œë ¥ ê°„ê²© (ë” ìì£¼)
    hooks=[
        dict(type='TextLoggerHook'),
        dict(type='TensorboardLoggerHook'),
    ])

# runtime settings
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/stgcnpp_enhanced_augmented_fight_detection'
load_from = None
resume_from = None
workflow = [('train', 1)]

# ğŸ¯ í•µì‹¬ ê°œì„ ì‚¬í•­ ìš”ì•½:
# 1. Dense training data: 16,371 segments (2.8x more)
# 2. 7ê°€ì§€ ë°ì´í„° ì¦ê°•: flip, rotation, scale, shear, jitter, occlusion, temporal
# 3. í•™ìŠµ/ì¶”ë¡  ë°ì´í„° ë¶„ë¦¬: dense training, sparse inference
# 4. í–¥ìƒëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°: ë†’ì€ í•™ìŠµë¥ , ê¸´ í•™ìŠµ, ì½”ì‚¬ì¸ ìŠ¤ì¼€ì¤„ë§