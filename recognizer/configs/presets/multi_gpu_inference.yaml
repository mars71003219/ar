# 멀티GPU 추론 프리셋
# 사용법: python main.py --config configs/presets/multi_gpu_inference.yaml --input video.mp4

execution:
  mode: "inference"
  output_dir: "output/multi_gpu_inference"

features:
  enable_evaluation: true
  enable_visualization: true

performance:
  device: "cuda:0"  # 메인 디바이스
  
  # 멀티GPU 활성화
  multi_gpu:
    enable: true              # 멀티GPU 활성화
    gpus: [0, 1, 2, 3]       # 4개 GPU 사용
    strategy: "data_parallel"
    batch_per_gpu: 2         # GPU당 배치 크기 증가
  
  batch_size: 8              # 전체 배치 크기
  mixed_precision: true      # 성능 향상