# ONNX ìµœì í™” ì¸ì ì™„ì „ ì°¸ì¡° ê°€ì´ë“œ

14ê°€ì§€ ì¡°í•©ì— ì‚¬ìš©ëœ ê° ì¸ìì˜ ì •ì˜, ë™ì‘ ì›ë¦¬, ì„±ëŠ¥ ì˜í–¥ì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ“‹ ì¸ì ë¶„ë¥˜

### ğŸ§  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
- `cudnn_conv_algo_search`: cuDNN ì»¨ë³¼ë£¨ì…˜ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ ë°©ì‹
- `execution_mode`: ONNXRuntime ì‹¤í–‰ ëª¨ë“œ

### ğŸ’¾ ë©”ëª¨ë¦¬ ê´€ë¦¬  
- `gpu_mem_limit_gb`: GPU ë©”ëª¨ë¦¬ í• ë‹¹ í•œê³„
- `arena_extend_strategy`: ë©”ëª¨ë¦¬ ì•„ë ˆë‚˜ í™•ì¥ ì „ëµ
- `enable_cpu_mem_arena`: CPU ë©”ëª¨ë¦¬ ì•„ë ˆë‚˜ í™œì„±í™”
- `enable_mem_pattern`: ë©”ëª¨ë¦¬ íŒ¨í„´ ìµœì í™”

### âš¡ ì„±ëŠ¥ ìµœì í™”
- `do_copy_in_default_stream`: CUDA ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ
- `cudnn_conv_use_max_workspace`: cuDNN ì‘ì—…ê³µê°„ í¬ê¸°
- `tunable_op_enable`: ë™ì  ì—°ì‚° ìµœì í™”
- `graph_optimization_level`: ê·¸ë˜í”„ ìµœì í™” ìˆ˜ì¤€

---

## ğŸ§  ì•Œê³ ë¦¬ì¦˜ ì„ íƒ ì¸ì

### `cudnn_conv_algo_search`

cuDNNì´ ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°ì— ì‚¬ìš©í•  ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•˜ëŠ” ë°©ì‹ì„ ê²°ì •í•©ë‹ˆë‹¤.

#### ì˜µì…˜ë³„ ìƒì„¸ ë™ì‘

**`"HEURISTIC"` (íœ´ë¦¬ìŠ¤í‹±)**
```cpp
// cuDNN ë‚´ë¶€ ì˜ì‚¬ì½”ë“œ
Algorithm selectConvolutionAlgorithm(TensorDesc input, FilterDesc filter) {
    // 1. ì…ë ¥ íŠ¹ì„± ë¶„ì„
    int input_size = input.height * input.width;
    int channels = input.channels;
    int filter_size = filter.height * filter.width;
    
    // 2. GPU ì•„í‚¤í…ì²˜ ê³ ë ¤
    if (gpu_arch == AMPERE && input_size > 300*300) {
        if (filter_size <= 3) {
            return ALGO_WINOGRAD_NONFUSED;  // í° ì…ë ¥ + ì‘ì€ í•„í„°
        } else {
            return ALGO_IMPLICIT_GEMM;      // í° ì…ë ¥ + í° í•„í„°  
        }
    } else if (gpu_arch == TURING) {
        return ALGO_DIRECT_CONVOLUTION;     // ì•ˆì •ì  ì„ íƒ
    }
    
    // 3. ë©”ëª¨ë¦¬ ëŒ€ì—­í­ ê³ ë ¤
    if (memory_bandwidth_limited) {
        return memory_efficient_algorithm();
    } else {
        return compute_intensive_algorithm();
    }
}
```
- **ì¥ì **: ë¹ ë¥¸ ì„ íƒ (1-2ms), ì‹¤ìš©ì  ì„±ëŠ¥, ë©”ëª¨ë¦¬ íš¨ìœ¨ì 
- **ë‹¨ì **: ì´ë¡ ì  ìµœì ì´ ì•„ë‹ ìˆ˜ ìˆìŒ
- **ì í•©í•œ í™˜ê²½**: ì‹¤ì‹œê°„ ì¶”ë¡ , í”„ë¡œë•ì…˜ í™˜ê²½

**`"EXHAUSTIVE"` (ì „ìˆ˜íƒìƒ‰)**
```cpp
// cuDNN ë‚´ë¶€ ì˜ì‚¬ì½”ë“œ  
Algorithm selectConvolutionAlgorithm(TensorDesc input, FilterDesc filter) {
    vector<Algorithm> available_algos = {
        ALGO_IMPLICIT_GEMM,
        ALGO_IMPLICIT_PRECOMP_GEMM, 
        ALGO_GEMM,
        ALGO_DIRECT,
        ALGO_FFT,
        ALGO_FFT_TILING,
        ALGO_WINOGRAD,
        ALGO_WINOGRAD_NONFUSED
    };
    
    Algorithm best_algo;
    float best_time = INFINITY;
    
    // ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ ì‹¤ì œ ì‹¤í–‰í•˜ì—¬ ì¸¡ì •
    for (auto algo : available_algos) {
        try {
            float exec_time = benchmark_algorithm(algo, input, filter, actual_data);
            if (exec_time < best_time) {
                best_time = exec_time;
                best_algo = algo;
            }
        } catch (OutOfMemoryError) {
            continue;  // ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ ìŠ¤í‚µ
        }
    }
    
    return best_algo;  // ì‹¤ì œ ì¸¡ì •ìœ¼ë¡œ ì°¾ì€ ìµœì  ì•Œê³ ë¦¬ì¦˜
}
```
- **ì¥ì **: ì´ë¡ ì  ìµœì  ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
- **ë‹¨ì **: ì´ˆê¸°í™” ì˜¤ë˜ ê±¸ë¦¼ (2-5ì´ˆ), ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©
- **ì í•©í•œ í™˜ê²½**: ë°°ì¹˜ ì²˜ë¦¬, ì¥ì‹œê°„ ì‹¤í–‰

**`"DEFAULT"` (ê¸°ë³¸)**
```cpp
// cuDNN ë‚´ë¶€ ì˜ì‚¬ì½”ë“œ
Algorithm selectConvolutionAlgorithm(TensorDesc input, FilterDesc filter) {
    // GPUë³„ ê¸°ë³¸ ì•Œê³ ë¦¬ì¦˜ ë°˜í™˜
    if (gpu_arch == AMPERE) {
        return ALGO_IMPLICIT_GEMM;  // Ampere ê¸°ë³¸
    } else if (gpu_arch == TURING) {
        return ALGO_DIRECT_CONVOLUTION;  // Turing ê¸°ë³¸
    } else {
        return ALGO_GEMM;  // ë²”ìš© ê¸°ë³¸
    }
}
```
- **ì¥ì **: ë¹ ë¥¸ ì´ˆê¸°í™”, ì•ˆì •ì 
- **ë‹¨ì **: ìµœì í™”ë˜ì§€ ì•Šì€ ì„±ëŠ¥
- **ì í•©í•œ í™˜ê²½**: í…ŒìŠ¤íŠ¸, ë””ë²„ê¹…, í˜¸í™˜ì„± ìš°ì„ 

---

## ğŸ’¾ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì¸ì

### `gpu_mem_limit_gb`

ONNXRuntimeì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ GPU ë©”ëª¨ë¦¬ë¥¼ ì œí•œí•©ë‹ˆë‹¤.

```python
# ë©”ëª¨ë¦¬ í• ë‹¹ ê³„ì‚°
total_gpu_memory = 24GB  # RTX A5000
allocation_options = [
    4GB,   # 17% (ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ì™€ ê³µìœ )
    8GB,   # 33% (ì¼ë°˜ì  ê¶Œì¥)
    16GB,  # 67% (ê³ ì„±ëŠ¥)
    21GB,  # 88% (ë‹¨ë… ì‚¬ìš©)
]
```

**ë©”ëª¨ë¦¬ í¬ê¸°ë³„ íŠ¹ì„±:**

**4GB (ë³´ìˆ˜ì )**
```
ì¥ì : 
- ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ì™€ GPU ê³µìœ  ê°€ëŠ¥
- ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜ ìœ„í—˜ ë‚®ìŒ
- ì•ˆì •ì ì¸ ìš´ì˜

ë‹¨ì :
- í° ëª¨ë¸ì´ë‚˜ ë°°ì¹˜ ì²˜ë¦¬ ì œì•½
- ì„±ëŠ¥ ìµœì í™” ì œí•œ
```

**8GB (ê· í˜•)**
```
ì¥ì :
- ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì˜ ê· í˜•
- ëŒ€ë¶€ë¶„ ëª¨ë¸ì— ì¶©ë¶„
- ê¶Œì¥ ì„¤ì •

ë‹¨ì :
- ë§¤ìš° í° ëª¨ë¸ì—ëŠ” ë¶€ì¡±í•  ìˆ˜ ìˆìŒ
```

**16-21GB (ê³ ì„±ëŠ¥)**
```
ì¥ì :
- ìµœëŒ€ ì„±ëŠ¥ ë°œíœ˜ ê°€ëŠ¥
- ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ê°€ëŠ¥
- ë©”ëª¨ë¦¬ ë‹¨í¸í™” ìµœì†Œí™”

ë‹¨ì :
- ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ ì‚¬ìš© ë¶ˆê°€
- ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ ì‹œìŠ¤í…œ ë¶ˆì•ˆì •
```

### `arena_extend_strategy`

GPU ë©”ëª¨ë¦¬ ì•„ë ˆë‚˜(ì—°ì†ëœ ë©”ëª¨ë¦¬ ë¸”ë¡)ë¥¼ í™•ì¥í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤.

**`"kNextPowerOfTwo"` (2^n í™•ì¥)**
```cpp
// CUDA ë©”ëª¨ë¦¬ í• ë‹¹ ì˜ì‚¬ì½”ë“œ
size_t calculateArenaSize(size_t requested_size) {
    // ìš”ì²­ëœ í¬ê¸°ë³´ë‹¤ í° 2ì˜ ê±°ë“­ì œê³±ìœ¼ë¡œ í™•ì¥
    size_t power_of_two = 1;
    while (power_of_two < requested_size) {
        power_of_two *= 2;
    }
    return power_of_two;
}

// ì˜ˆì‹œ: 640MB ìš”ì²­ â†’ 1024MB í• ë‹¹
```
- **ì¥ì **: ë©”ëª¨ë¦¬ ë‹¨í¸í™” ìµœì†Œí™”, ì¬í• ë‹¹ ë¹ˆë„ ê°ì†Œ
- **ë‹¨ì **: ë©”ëª¨ë¦¬ ë‚­ë¹„ ê°€ëŠ¥ì„±
- **ì í•©**: ì¼ì •í•œ í¬ê¸°ì˜ ë°˜ë³µ ì²˜ë¦¬

**`"kSameAsRequested"` (ìš”ì²­ í¬ê¸°ë§Œí¼)**
```cpp
size_t calculateArenaSize(size_t requested_size) {
    return requested_size;  // ì •í™•íˆ ìš”ì²­ëœ í¬ê¸°ë§Œ í• ë‹¹
}

// ì˜ˆì‹œ: 640MB ìš”ì²­ â†’ 640MB í• ë‹¹
```
- **ì¥ì **: ë©”ëª¨ë¦¬ ì ˆì•½, ì •í™•í•œ í• ë‹¹
- **ë‹¨ì **: ì¬í• ë‹¹ ë¹ˆë„ ì¦ê°€, ë‹¨í¸í™” ê°€ëŠ¥
- **ì í•©**: ê°€ë³€ í¬ê¸° ì²˜ë¦¬, ë©”ëª¨ë¦¬ ì œì•½ í™˜ê²½

---

## âš¡ ì„±ëŠ¥ ìµœì í™” ì¸ì

### `do_copy_in_default_stream`

CPU-GPU ê°„ ë°ì´í„° ë³µì‚¬ë¥¼ ì–´ëŠ CUDA ìŠ¤íŠ¸ë¦¼ì—ì„œ ìˆ˜í–‰í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.

**`false` (ë³„ë„ ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©) - ê¶Œì¥**
```cpp
// CUDA ìŠ¤íŠ¸ë¦¼ ê´€ë¦¬ ì˜ì‚¬ì½”ë“œ
cudaStream_t main_stream;      // ì¶”ë¡ ìš© ìŠ¤íŠ¸ë¦¼
cudaStream_t copy_stream;      // ë°ì´í„° ë³µì‚¬ìš© ìŠ¤íŠ¸ë¦¼

// ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥
cudaMemcpyAsync(gpu_input, cpu_input, size, copy_stream);  // ë³µì‚¬
kernel_inference<<<blocks, threads, 0, main_stream>>>();   // ì¶”ë¡ 

// ìŠ¤íŠ¸ë¦¼ ë™ê¸°í™”
cudaStreamSynchronize(copy_stream);
cudaStreamSynchronize(main_stream);
```
- **ì¥ì **: ë°ì´í„° ë³µì‚¬ì™€ ì¶”ë¡  ë³‘ë ¬ ì²˜ë¦¬, ì²˜ë¦¬ëŸ‰ í–¥ìƒ
- **ë‹¨ì **: ë³µì¡í•œ ë™ê¸°í™”, ë””ë²„ê¹… ì–´ë ¤ì›€
- **ì„±ëŠ¥ í–¥ìƒ**: 5-15% (ë°ì´í„° í¬ê¸°ì— ë”°ë¼)

**`true` (ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©)**
```cpp
// ìˆœì°¨ ì²˜ë¦¬
cudaMemcpy(gpu_input, cpu_input, size);  // ë³µì‚¬ ì™„ë£Œ ëŒ€ê¸°
kernel_inference<<<blocks, threads>>>();  // ì¶”ë¡  ì‹œì‘
cudaDeviceSynchronize();                  // ì™„ë£Œ ëŒ€ê¸°
```
- **ì¥ì **: ë‹¨ìˆœí•œ êµ¬ì¡°, ë””ë²„ê¹… ìš©ì´
- **ë‹¨ì **: ìˆœì°¨ ì²˜ë¦¬ë¡œ ì¸í•œ ì„±ëŠ¥ ì†ì‹¤
- **ì„±ëŠ¥**: ê¸°ë³¸ ìˆ˜ì¤€

### `cudnn_conv_use_max_workspace`

cuDNNì´ ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì„ì‹œ ì‘ì—…ê³µê°„ í¬ê¸°ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.

**`true` (ìµœëŒ€ ì‘ì—…ê³µê°„) - ì„±ëŠ¥ ìš°ì„ **
```cpp
// cuDNN ì‘ì—…ê³µê°„ í• ë‹¹ ì˜ì‚¬ì½”ë“œ
size_t getWorkspaceSize(ConvolutionDesc desc) {
    if (use_max_workspace) {
        // ì‚¬ìš© ê°€ëŠ¥í•œ ìµœëŒ€ ë©”ëª¨ë¦¬ì˜ 80% ì‚¬ìš©
        return available_gpu_memory * 0.8;
    } else {
        // ìµœì†Œ í•„ìš”í•œ ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš©
        return minimum_required_memory;
    }
}
```
- **ì¥ì **: ìµœê³  ì„±ëŠ¥ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© ê°€ëŠ¥, FFT/Winograd í™œì„±í™”
- **ë‹¨ì **: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€, OOM ìœ„í—˜
- **ì„±ëŠ¥ í–¥ìƒ**: 10-30% (ì•Œê³ ë¦¬ì¦˜ ì¢…ë¥˜ì— ë”°ë¼)

**`false` (ìµœì†Œ ì‘ì—…ê³µê°„) - ë©”ëª¨ë¦¬ ì ˆì•½**
- **ì¥ì **: ë©”ëª¨ë¦¬ ì ˆì•½, ì•ˆì •ì„±
- **ë‹¨ì **: ê³ ì„±ëŠ¥ ì•Œê³ ë¦¬ì¦˜ ì œí•œ
- **ì„±ëŠ¥**: ê¸°ë³¸ ìˆ˜ì¤€

### `tunable_op_enable` & `tunable_op_tuning_enable`

ëŸ°íƒ€ì„ì— GPUë³„ íŠ¹ì„±ì— ë§ê²Œ ì—°ì‚°ì„ ë™ì ìœ¼ë¡œ ìµœì í™”í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.

**ë™ì‘ ì›ë¦¬:**
```python
# TunableOp ì˜ì‚¬ì½”ë“œ
class TunableConvolution:
    def __init__(self):
        self.algorithms = [GEMM, DIRECT, WINOGRAD, FFT]
        self.performance_cache = {}
    
    def execute(self, input_tensor):
        key = (input_tensor.shape, self.filter.shape)
        
        if key not in self.performance_cache:
            # ì²« ì‹¤í–‰ì‹œ: ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸
            best_algo = self.find_best_algorithm(input_tensor)
            self.performance_cache[key] = best_algo
        
        # ìºì‹œëœ ìµœì  ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
        return self.performance_cache[key].execute(input_tensor)
```

**`tunable_op_enable: true`**
- **ê¸°ëŠ¥**: ëŸ°íƒ€ì„ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ í™œì„±í™”
- **ì˜¤ë²„í—¤ë“œ**: ì²« ì‹¤í–‰ì‹œ ì¶”ê°€ ì‹œê°„ (100-500ms)
- **ì´í›„ ì„±ëŠ¥**: ìºì‹œëœ ìµœì  ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í–¥ìƒ

**`tunable_op_tuning_enable: true`**  
- **ê¸°ëŠ¥**: ì§€ì†ì ì¸ ì„±ëŠ¥ íŠœë‹
- **ë™ì‘**: ì‹¤í–‰ ì¤‘ ë” ë‚˜ì€ ì•Œê³ ë¦¬ì¦˜ íƒìƒ‰
- **ì ì‘ì„±**: ì…ë ¥ íŒ¨í„´ ë³€í™”ì— ëŒ€ì‘

---

## ğŸ—ï¸ ì‹¤í–‰ ëª¨ë“œ ì¸ì

### `execution_mode`

ONNXRuntimeì´ ê·¸ë˜í”„ì˜ ë…¸ë“œë“¤ì„ ì‹¤í–‰í•˜ëŠ” ë°©ì‹ì„ ê²°ì •í•©ë‹ˆë‹¤.

**`"ORT_SEQUENTIAL"` (ìˆœì°¨ ì‹¤í–‰) - ê¶Œì¥**
```cpp
// ìˆœì°¨ ì‹¤í–‰ ì˜ì‚¬ì½”ë“œ
void executeGraph(Graph graph) {
    for (Node node : graph.getTopologicalOrder()) {
        // ë…¸ë“œë¥¼ í•˜ë‚˜ì”© ìˆœì„œëŒ€ë¡œ ì‹¤í–‰
        executeNode(node);
        waitForCompletion(node);  // ì™„ë£Œ ëŒ€ê¸°
    }
}
```
- **íŠ¹ì§•**: ë…¸ë“œë¥¼ í•˜ë‚˜ì”© ìˆœì„œëŒ€ë¡œ ì‹¤í–‰
- **ì¥ì **: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡ ê°€ëŠ¥, ë””ë²„ê¹… ìš©ì´, ì•ˆì •ì 
- **ë‹¨ì **: ë³‘ë ¬ì„± ì œí•œ
- **ì í•©**: ëŒ€ë¶€ë¶„ì˜ ì¶”ë¡  ì‘ì—…, ë©”ëª¨ë¦¬ ì œì•½ í™˜ê²½

**`"ORT_PARALLEL"` (ë³‘ë ¬ ì‹¤í–‰)**
```cpp
// ë³‘ë ¬ ì‹¤í–‰ ì˜ì‚¬ì½”ë“œ
void executeGraph(Graph graph) {
    ThreadPool thread_pool;
    
    for (Node node : graph.getNodes()) {
        if (node.canExecuteInParallel()) {
            thread_pool.submit([&]() {
                executeNode(node);  // ë³‘ë ¬ ì‹¤í–‰
            });
        } else {
            executeNode(node);  // ìˆœì°¨ ì‹¤í–‰
        }
    }
    
    thread_pool.waitAll();  // ëª¨ë“  ë…¸ë“œ ì™„ë£Œ ëŒ€ê¸°
}
```
- **íŠ¹ì§•**: ë…ë¦½ì ì¸ ë…¸ë“œë“¤ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
- **ì¥ì **: ë†’ì€ ì²˜ë¦¬ëŸ‰, GPU í™œìš©ë¥  í–¥ìƒ
- **ë‹¨ì **: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€, ë™ê¸°í™” ë³µì¡
- **ì í•©**: ë³µì¡í•œ ê·¸ë˜í”„, ê³ ì„±ëŠ¥ GPU

### `graph_optimization_level`

ONNX ê·¸ë˜í”„ì— ì ìš©í•  ìµœì í™” ìˆ˜ì¤€ì„ ê²°ì •í•©ë‹ˆë‹¤.

**`"ORT_ENABLE_ALL"` (ëª¨ë“  ìµœì í™”) - ê¶Œì¥**
```cpp
// ê·¸ë˜í”„ ìµœì í™” ì ìš© ì˜ì‚¬ì½”ë“œ
Graph optimizeGraph(Graph original_graph) {
    Graph optimized = original_graph;
    
    // 1. ë…¸ë“œ ìœµí•© (Node Fusion)
    optimized = fuseConvBatchNormRelu(optimized);
    optimized = fuseMatMulAdd(optimized);
    
    // 2. ìƒìˆ˜ ì ‘ê¸° (Constant Folding)
    optimized = foldConstants(optimized);
    
    // 3. ë¶ˆí•„ìš”í•œ ì—°ì‚° ì œê±°
    optimized = eliminateDeadNodes(optimized);
    
    // 4. ì—°ì‚° ì¬ë°°ì¹˜ (Operator Reordering)
    optimized = reorderForMemoryEfficiency(optimized);
    
    // 5. ë©”ëª¨ë¦¬ ìµœì í™”
    optimized = optimizeMemoryLayout(optimized);
    
    return optimized;
}
```
- **ìµœì í™” ì¢…ë¥˜**: ë…¸ë“œ ìœµí•©, ìƒìˆ˜ ì ‘ê¸°, ë°ë“œ ì½”ë“œ ì œê±°, ì—°ì‚° ì¬ë°°ì¹˜
- **ì„±ëŠ¥ í–¥ìƒ**: 10-40% (ëª¨ë¸ ë³µì¡ë„ì— ë”°ë¼)
- **ë©”ëª¨ë¦¬ ì ˆì•½**: ì¤‘ê°„ ê²°ê³¼ ì œê±°ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ

**`"ORT_ENABLE_BASIC"` (ê¸°ë³¸ ìµœì í™”)**
- **ìµœì í™”**: ê¸°ë³¸ì ì¸ ìœµí•©ê³¼ ì ‘ê¸°ë§Œ ìˆ˜í–‰
- **ì¥ì **: ë¹ ë¥¸ ì´ˆê¸°í™”, í˜¸í™˜ì„±
- **ë‹¨ì **: ì œí•œëœ ì„±ëŠ¥ í–¥ìƒ

---

## ğŸ’¾ ë©”ëª¨ë¦¬ ìµœì í™” ì¸ì

### `enable_cpu_mem_arena`

CPU ë©”ëª¨ë¦¬ ì•„ë ˆë‚˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ í• ë‹¹ì„ ìµœì í™”í•©ë‹ˆë‹¤.

**`true` (ì•„ë ˆë‚˜ ì‚¬ìš©) - ê¶Œì¥**
```cpp
// ë©”ëª¨ë¦¬ ì•„ë ˆë‚˜ ì˜ì‚¬ì½”ë“œ
class MemoryArena {
    char* large_buffer;      // í° ì—°ì† ë©”ëª¨ë¦¬ ë¸”ë¡
    size_t current_offset;   // í˜„ì¬ í• ë‹¹ ìœ„ì¹˜
    
public:
    void* allocate(size_t size) {
        void* ptr = large_buffer + current_offset;
        current_offset += align(size);
        return ptr;  // ë§¤ìš° ë¹ ë¥¸ í• ë‹¹
    }
    
    void reset() {
        current_offset = 0;  // ì „ì²´ ë©”ëª¨ë¦¬ ì¬ì‚¬ìš©
    }
};
```
- **ì¥ì **: ë¹ ë¥¸ ë©”ëª¨ë¦¬ í• ë‹¹/í•´ì œ, ë‹¨í¸í™” ë°©ì§€
- **ë‹¨ì **: ì´ˆê¸° í° ë©”ëª¨ë¦¬ ë¸”ë¡ í•„ìš”
- **ì„±ëŠ¥ í–¥ìƒ**: 5-10% (ë©”ëª¨ë¦¬ ì§‘ì•½ì  ëª¨ë¸)

### `enable_mem_pattern`

ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì¬ì‚¬ìš©ì„ ìµœì í™”í•©ë‹ˆë‹¤.

**`true` (íŒ¨í„´ ìµœì í™”) - ê¶Œì¥**
```cpp
// ë©”ëª¨ë¦¬ íŒ¨í„´ ìµœì í™” ì˜ì‚¬ì½”ë“œ
class MemoryPatternOptimizer {
    map<TensorShape, void*> reusable_buffers;
    
public:
    void* getBuffer(TensorShape shape) {
        if (reusable_buffers.contains(shape)) {
            return reusable_buffers[shape];  // ì¬ì‚¬ìš©
        } else {
            void* new_buffer = allocate(shape.size());
            reusable_buffers[shape] = new_buffer;
            return new_buffer;
        }
    }
};
```
- **ê¸°ëŠ¥**: ë™ì¼í•œ í¬ê¸° í…ì„œì˜ ë©”ëª¨ë¦¬ ì¬ì‚¬ìš©
- **ì¥ì **: ë©”ëª¨ë¦¬ í• ë‹¹ íšŸìˆ˜ ê°ì†Œ, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ë¶€ë‹´ ì™„í™”
- **ì„±ëŠ¥ í–¥ìƒ**: 3-8% (ëª¨ë¸ êµ¬ì¡°ì— ë”°ë¼)

---

## ğŸ”„ 14ê°€ì§€ ì¡°í•© êµ¬ì„± ì›ë¦¬

### ì¡°í•© ìƒì„± ë¡œì§

```python
# ì‹¤ì œ ì¡°í•© ìƒì„± ì½”ë“œ
base_configs = [
    {
        'name': 'HEURISTIC_OPTIMIZED',
        'cudnn_conv_algo_search': 'HEURISTIC',
        'do_copy_in_default_stream': False,      # ì„±ëŠ¥ ìš°ì„ 
        'cudnn_conv_use_max_workspace': True,
        'tunable_op_enable': True,
        'execution_mode': 'ORT_SEQUENTIAL',
    },
    {
        'name': 'EXHAUSTIVE_BASELINE', 
        'cudnn_conv_algo_search': 'EXHAUSTIVE',
        'do_copy_in_default_stream': False,      # ì„±ëŠ¥ ìš°ì„ 
        'cudnn_conv_use_max_workspace': True,
        'tunable_op_enable': False,              # íƒìƒ‰ê³¼ ì¶©ëŒ ë°©ì§€
        'execution_mode': 'ORT_SEQUENTIAL',
    },
    {
        'name': 'DEFAULT_CONSERVATIVE',
        'cudnn_conv_algo_search': 'DEFAULT', 
        'do_copy_in_default_stream': True,       # ì•ˆì •ì„± ìš°ì„ 
        'cudnn_conv_use_max_workspace': False,
        'tunable_op_enable': False,
        'execution_mode': 'ORT_SEQUENTIAL',
    }
]

memory_limits = [4, 8, 16, 21]  # GPU ë©”ëª¨ë¦¬ë³„

# 3ê°œ ê¸°ë³¸ ì„¤ì • Ã— 4ê°œ ë©”ëª¨ë¦¬ í¬ê¸° = 12ê°œ ì¡°í•©
# + 2ê°œ ì‹¤í—˜ì  ì„¤ì • = 14ê°œ ì¡°í•©
```

### ì‹¤í—˜ì  ì¡°í•© (13-14ë²ˆ)

**ì¡°í•© 13: ë³‘ë ¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸**
```yaml
cudnn_conv_algo_search: "HEURISTIC"
execution_mode: "ORT_PARALLEL"        # ë³‘ë ¬ ëª¨ë“œ
gpu_mem_limit_gb: 21                  # ìµœëŒ€ ë©”ëª¨ë¦¬
enable_cpu_mem_arena: False           # ë³‘ë ¬ì— ìµœì í™”
```

**ì¡°í•© 14: ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œ**
```yaml
cudnn_conv_algo_search: "HEURISTIC"
gpu_mem_limit_gb: 4                   # ìµœì†Œ ë©”ëª¨ë¦¬
do_copy_in_default_stream: True       # ë‹¨ìˆœ ëª¨ë“œ
cudnn_conv_use_max_workspace: False   # ë©”ëª¨ë¦¬ ì ˆì•½
```

## ğŸ“Š ì¸ìë³„ ì„±ëŠ¥ ì˜í–¥ë„

| ì¸ì | ì„±ëŠ¥ ì˜í–¥ | ë©”ëª¨ë¦¬ ì˜í–¥ | ì•ˆì •ì„± ì˜í–¥ | ê¶Œì¥ë„ |
|------|----------|-------------|-------------|---------|
| `cudnn_conv_algo_search` | â­â­â­â­â­ | â­â­â­ | â­â­â­ | HEURISTIC |
| `do_copy_in_default_stream` | â­â­â­â­ | â­ | â­â­ | False |
| `gpu_mem_limit_gb` | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | 8GB |
| `cudnn_conv_use_max_workspace` | â­â­â­ | â­â­â­â­ | â­â­ | True |
| `execution_mode` | â­â­ | â­â­â­ | â­â­â­â­ | SEQUENTIAL |
| `tunable_op_enable` | â­â­ | â­ | â­â­â­ | True |

## ğŸ’¡ ì‹¤ì œ ì‚¬ìš© ê¶Œì¥ì‚¬í•­

### ìƒˆë¡œìš´ GPU í™˜ê²½ ìµœì í™” ì ˆì°¨

1. **ìë™ ìµœì í™” ì‹¤í–‰**
   ```bash
   python tools/onnx_optimizer.py --model model.onnx --config config.yaml
   ```

2. **ê²°ê³¼ ê²€ì¦**
   ```bash
   # ìµœì í™” ì „í›„ ì„±ëŠ¥ ë¹„êµ
   python test_rtmo_performance.py
   ```

3. **í”„ë¡œë•ì…˜ ì ìš©**
   ```bash
   # config.yamlì´ ìë™ ì—…ë°ì´íŠ¸ë¨
   # ë°”ë¡œ í”„ë¡œë•ì…˜ì—ì„œ ì‚¬ìš© ê°€ëŠ¥
   ```

### GPUë³„ ì˜ˆìƒ ìµœì  ì„¤ì •

**ê³ ì„±ëŠ¥ GPU (RTX 4090, A100)**
```yaml
cudnn_conv_algo_search: "HEURISTIC"
gpu_mem_limit_gb: 16-24
do_copy_in_default_stream: false
cudnn_conv_use_max_workspace: true
tunable_op_enable: true
```

**ì¤‘ê¸‰ GPU (RTX 3080, A5000)**
```yaml
cudnn_conv_algo_search: "HEURISTIC"  
gpu_mem_limit_gb: 8-12
do_copy_in_default_stream: false
cudnn_conv_use_max_workspace: true
tunable_op_enable: true
```

**ì—”íŠ¸ë¦¬ GPU (RTX 3060, T4)**
```yaml
cudnn_conv_algo_search: "DEFAULT"
gpu_mem_limit_gb: 4-6
do_copy_in_default_stream: true
cudnn_conv_use_max_workspace: false
tunable_op_enable: false
```

---

**ì´ ë¬¸ì„œëŠ” ìë™ ìµœì í™” ë„êµ¬ì™€ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  GPU í™˜ê²½ì—ì„œ ìµœì  ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.**