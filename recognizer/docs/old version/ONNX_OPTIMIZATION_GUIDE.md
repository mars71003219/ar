# ONNX GPU ìµœì í™” ì™„ì „ ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” ë‹¤ì–‘í•œ GPU í™˜ê²½ì—ì„œ RTMO ONNX ëª¨ë¸ì˜ ìµœì  ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•œ ìžë™ ìµœì í™” ë„êµ¬ì™€ ê·¸ ìž‘ë™ ì›ë¦¬ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.

## ðŸŽ¯ ë°°ê²½ ë° ëª©ì 

### ë¬¸ì œ ìƒí™©
- ë‹¤ì–‘í•œ GPU í™˜ê²½ (RTX 3090, RTX 4090, A5000, V100 ë“±)ì—ì„œ ì„±ëŠ¥ ì°¨ì´ ë°œìƒ
- ONNX ì„¤ì •ì´ GPUë³„ë¡œ ë‹¤ë¥¸ ìµœì ê°’ì„ ê°€ì§
- ìˆ˜ë™ íŠœë‹ì˜ í•œê³„ì™€ ì‹œê°„ ì†Œìš”

### í•´ê²° ë°©ì•ˆ
- **ìžë™ ë²¤ì¹˜ë§ˆí‚¹ ë„êµ¬**: GPUë³„ ìµœì  ì„¤ì • ìžë™ íƒì§€
- **Grid Search**: ì²´ê³„ì ì¸ ì„¤ì • ì¡°í•© íƒìƒ‰
- **ìžë™ ì„¤ì • ì ìš©**: config.yaml ìžë™ ì—…ë°ì´íŠ¸

## ðŸ”§ ìžë™ ìµœì í™” ë„êµ¬ ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‚¬ìš©ë²•
```bash
# ê¸°ë³¸ ìµœì í™” (ê¶Œìž¥)
python tools/onnx_optimizer.py \
    --model /path/to/model.onnx \
    --config /path/to/config.yaml \
    --output optimization_report.md

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ì ì€ ì¡°í•©)
python tools/onnx_optimizer.py \
    --model /path/to/model.onnx \
    --quick

# ì •ë°€ ì¸¡ì • (ë” ë§Žì€ ë°˜ë³µ)
python tools/onnx_optimizer.py \
    --model /path/to/model.onnx \
    --warmup 50 \
    --runs 100
```

### ì¶œë ¥ ê²°ê³¼
- **ìžë™ config.yaml ì—…ë°ì´íŠ¸**: ìµœì  ì„¤ì • ìžë™ ì ìš©
- **ìƒì„¸ ë³´ê³ ì„œ**: ì„±ëŠ¥ ë¶„ì„ ë° ê¶Œìž¥ì‚¬í•­ (.md íŒŒì¼)
- **ì‹¤ì‹œê°„ ë¡œê·¸**: ì§„í–‰ìƒí™© ë° ê²°ê³¼ í™•ì¸

## ðŸ“Š ìµœì í™” ë§¤ê°œë³€ìˆ˜ ì„¤ëª…

### 1. cuDNN Convolution Algorithm Search

#### `cudnn_conv_algo_search`
```yaml
# ì˜µì…˜: 'DEFAULT', 'HEURISTIC', 'EXHAUSTIVE'
cudnn_conv_algo_search: "HEURISTIC"  # ê¶Œìž¥
```

**ê° ì•Œê³ ë¦¬ì¦˜ì˜ íŠ¹ì„±:**

| ì•Œê³ ë¦¬ì¦˜ | ì´ˆê¸°í™” ì‹œê°„ | ì¶”ë¡  ì„±ëŠ¥ | ë©”ëª¨ë¦¬ ì‚¬ìš© | ê¶Œìž¥ í™˜ê²½ |
|----------|-------------|-----------|-------------|-----------|
| **HEURISTIC** | ë¹ ë¦„ (~0.3ì´ˆ) | ìš°ìˆ˜ | ì ìŒ | ì‹¤ì‹œê°„, í”„ë¡œë•ì…˜ |
| **EXHAUSTIVE** | ëŠë¦¼ (~4ì´ˆ) | ë³€ìˆ˜ì  | ë§ŽìŒ | ë°°ì¹˜ ì²˜ë¦¬ |
| **DEFAULT** | ë§¤ìš° ë¹ ë¦„ | ë³´í†µ | ì ìŒ | í…ŒìŠ¤íŠ¸, ë””ë²„ê¹… |

**HEURISTICì˜ ë™ìž‘ ì›ë¦¬:**
```
1. ìž…ë ¥ í…ì„œ ë¶„ì„ (í¬ê¸°, ì±„ë„, ë°°ì¹˜)
   â†’ [1, 3, 640, 640] ë¶„ì„
   
2. GPU ì•„í‚¤í…ì²˜ íŠ¹ì„± ê³ ë ¤
   â†’ RTX A5000: 8192 CUDA cores, Ampere ì•„í‚¤í…ì²˜
   
3. ê²½í—˜ì  ê·œì¹™ ì ìš©
   â†’ í° ìž…ë ¥ + ì ì€ ì±„ë„ â†’ WINOGRAD ê³„ì—´ ì„ íƒ
   
4. ë¹ ë¥¸ ê²€ì¦ ë° í™•ì •
   â†’ ìˆ˜ ë°€ë¦¬ì´ˆ ë‚´ ê²°ì •
```

**EXHAUSTIVEì˜ ë™ìž‘ ì›ë¦¬:**
```
1. ëª¨ë“  cuDNN ì•Œê³ ë¦¬ì¦˜ ë‚˜ì—´
   â†’ IMPLICIT_GEMM, WINOGRAD, DIRECT ë“± 8-12ê°€ì§€
   
2. ê° ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì‹¤ì œ ì¶”ë¡  ì‹¤í–‰
   â†’ ì‹¤ì œ ìž…ë ¥ìœ¼ë¡œ ì„±ëŠ¥ ì¸¡ì •
   
3. ê°€ìž¥ ë¹ ë¥¸ ê²ƒ ì„ íƒ
   â†’ í•˜ì§€ë§Œ ì¸¡ì • í™˜ê²½ê³¼ ì‹¤ì œ í™˜ê²½ì˜ ì°¨ì´ ë°œìƒ ê°€ëŠ¥
   
4. ì•Œê³ ë¦¬ì¦˜ ê³ ì •
   â†’ ì´í›„ ì„ íƒëœ ì•Œê³ ë¦¬ì¦˜ë§Œ ì‚¬ìš©
```

### 2. GPU ë©”ëª¨ë¦¬ ê´€ë¦¬

#### `gpu_mem_limit_gb`
```yaml
gpu_mem_limit_gb: 8  # GPU ë©”ëª¨ë¦¬ì˜ 30-40% ê¶Œìž¥
```

**ë©”ëª¨ë¦¬ í• ë‹¹ ì „ëžµ:**
- **ì ì€ í• ë‹¹ (4GB)**: ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ì™€ ê³µìœ , ì•ˆì •ì„± ìš°ì„ 
- **ì¤‘ê°„ í• ë‹¹ (8-16GB)**: ê· í˜•ìž¡ížŒ ì„±ëŠ¥, ì¼ë°˜ì  ê¶Œìž¥
- **í° í• ë‹¹ (20GB+)**: ìµœëŒ€ ì„±ëŠ¥, ë‹¨ë… ì‚¬ìš©ì‹œ

#### `arena_extend_strategy`
```yaml
arena_extend_strategy: "kNextPowerOfTwo"  # ê¶Œìž¥
```

**ì „ëžµ ë¹„êµ:**
- **kNextPowerOfTwo**: 2^n í¬ê¸°ë¡œ í™•ìž¥, ë©”ëª¨ë¦¬ ë‹¨íŽ¸í™” ìµœì†Œí™”
- **kSameAsRequested**: ìš”ì²­ í¬ê¸°ë§Œí¼ë§Œ í• ë‹¹, ë©”ëª¨ë¦¬ ì ˆì•½

### 3. ìŠ¤íŠ¸ë¦¼ ë° ë™ê¸°í™”

#### `do_copy_in_default_stream`
```yaml
do_copy_in_default_stream: false  # ì„±ëŠ¥ ìµœì í™”
```

**ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ ë¹„êµ:**
- **false**: ë³„ë„ CUDA ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©, ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
- **true**: ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©, ë‹¨ìˆœí•˜ì§€ë§Œ ë³‘ëª© ê°€ëŠ¥

### 4. cuDNN ìž‘ì—…ê³µê°„

#### `cudnn_conv_use_max_workspace`
```yaml
cudnn_conv_use_max_workspace: true  # ì„±ëŠ¥ ìš°ì„ 
```

**ìž‘ì—…ê³µê°„ ì „ëžµ:**
- **true**: ìµœëŒ€ ìž‘ì—…ê³µê°„ ì‚¬ìš©, ìµœê³  ì„±ëŠ¥
- **false**: ë©”ëª¨ë¦¬ ì ˆì•½, ì œí•œëœ í™˜ê²½

### 5. ë™ì  ìµœì í™”

#### `tunable_op_enable` & `tunable_op_tuning_enable`
```yaml
tunable_op_enable: true
tunable_op_tuning_enable: true
```

**ë™ì  íŠœë‹ ê¸°ëŠ¥:**
- ëŸ°íƒ€ìž„ì— ì—°ì‚° ìµœì í™”
- GPUë³„ íŠ¹ì„±ì— ë§žëŠ” ìžë™ ì¡°ì •
- ì´ˆê¸° ì˜¤ë²„í—¤ë“œ ìžˆì§€ë§Œ ìž¥ê¸°ì  ì„±ëŠ¥ í–¥ìƒ

## ðŸ—ï¸ ìµœì í™” í”„ë¡œì„¸ìŠ¤

### 1. í™˜ê²½ ë¶„ì„
```python
# GPU ì •ë³´ ìˆ˜ì§‘
gpu_name = torch.cuda.get_device_name(0)
gpu_memory = torch.cuda.get_device_properties(0).total_memory
compute_capability = torch.cuda.get_device_capability(0)
```

### 2. ì„¤ì • ì¡°í•© ìƒì„±
```python
# Grid Search ë§¤íŠ¸ë¦­ìŠ¤
algorithms = ['DEFAULT', 'HEURISTIC', 'EXHAUSTIVE']
memory_limits = [4GB, 8GB, 16GB, available_memory * 0.9]
stream_modes = [True, False]
workspace_modes = [True, False]

# ì´ 3 Ã— 4 Ã— 2 Ã— 2 = 48ê°€ì§€ ì¡°í•© í…ŒìŠ¤íŠ¸
```

### 3. ì„±ëŠ¥ ì¸¡ì •
```python
for config in all_combinations:
    # 1. ì„¸ì…˜ ìƒì„± (ì•Œê³ ë¦¬ì¦˜ ì„ íƒ)
    # 2. ì›Œë°ì—… (20íšŒ, ì•Œê³ ë¦¬ì¦˜ ì•ˆì •í™”)
    # 3. ì„±ëŠ¥ ì¸¡ì • (50íšŒ, í†µê³„ì  ì‹ ë¢°ì„±)
    # 4. ê²°ê³¼ ê¸°ë¡
```

### 4. ìµœì  ì„¤ì • ì„ íƒ
```python
# ì„±ê³µí•œ ì„¤ì • ì¤‘ FPS ê¸°ì¤€ ì •ë ¬
optimal = max(successful_results, key=lambda x: x.fps)
```

## ðŸ“ˆ ì„±ëŠ¥ ìµœì í™” ê²°ê³¼ ì˜ˆì‹œ

### RTX A5000ì—ì„œì˜ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

| ìˆœìœ„ | ì•Œê³ ë¦¬ì¦˜ | FPS | ì‹œê°„(ms) | ë©”ëª¨ë¦¬(GB) | íŠ¹ì§• |
|------|----------|-----|----------|------------|------|
| ðŸ¥‡ | HEURISTIC | 76.2 | 13.12 | 8 | **ìµœì ** |
| ðŸ¥ˆ | HEURISTIC | 76.0 | 13.16 | 21 | ë©”ëª¨ë¦¬ ì—¬ìœ  |
| ðŸ¥‰ | HEURISTIC | 75.8 | 13.19 | 16 | ê· í˜•ìž¡ížŒ |
| 4 | DEFAULT | 66.3 | 15.09 | 4 | ì•ˆì •ì  |
| 5 | EXHAUSTIVE | 45.2 | 22.13 | 8 | ì˜ˆìƒì™¸ ì €ì¡° |

### ì£¼ìš” ë°œê²¬ì‚¬í•­

1. **HEURISTIC > DEFAULT > EXHAUSTIVE**
   - RTX A5000ì—ì„œëŠ” íœ´ë¦¬ìŠ¤í‹±ì´ ê°€ìž¥ íš¨ìœ¨ì 
   - ì „ìˆ˜íƒìƒ‰ì´ ì˜¤ížˆë ¤ ë¹„íš¨ìœ¨ì 

2. **ë©”ëª¨ë¦¬ ì„¤ì •ì˜ ì˜í–¥**
   - 4-21GB ë²”ìœ„ì—ì„œ í° ì°¨ì´ ì—†ìŒ
   - 8GBê°€ ìµœì ì  (ì„±ëŠ¥ vs ì•ˆì •ì„±)

3. **ìŠ¤íŠ¸ë¦¼ ì„¤ì • ì¤‘ìš”ì„±**
   - `do_copy_in_default_stream: false`ê°€ í•µì‹¬
   - ë³„ë„ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”

## ðŸ”¬ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ ì „ëžµ

### GPU ì•„í‚¤í…ì²˜ë³„ ê²½í–¥

#### NVIDIA Ampere (RTX 30/40 ì‹œë¦¬ì¦ˆ, A ì‹œë¦¬ì¦ˆ)
```yaml
# ê¶Œìž¥ ì„¤ì •
cudnn_conv_algo_search: "HEURISTIC"
gpu_mem_limit_gb: 8-16
do_copy_in_default_stream: false
```
- í° í…ì„œ ì—°ì‚°ì— ìµœì í™”ëœ ì•„í‚¤í…ì²˜
- HEURISTICì´ Ampere íŠ¹ì„±ì„ ìž˜ í™œìš©

#### NVIDIA Turing (RTX 20 ì‹œë¦¬ì¦ˆ)
```yaml
# ê¶Œìž¥ ì„¤ì •  
cudnn_conv_algo_search: "DEFAULT"
gpu_mem_limit_gb: 4-8
do_copy_in_default_stream: true
```
- ìƒëŒ€ì ìœ¼ë¡œ ìž‘ì€ ë©”ëª¨ë¦¬, ë³´ìˆ˜ì  ì ‘ê·¼

#### NVIDIA Tesla (V100, T4)
```yaml
# ê¶Œìž¥ ì„¤ì •
cudnn_conv_algo_search: "EXHAUSTIVE"
gpu_mem_limit_gb: 12-16
do_copy_in_default_stream: false
```
- ë°ì´í„°ì„¼í„° ìµœì í™”, ë°°ì¹˜ ì²˜ë¦¬ì— íŠ¹í™”

## ðŸš€ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ê°œë°œ í™˜ê²½ì—ì„œ ë°°í¬ í™˜ê²½ìœ¼ë¡œ
```bash
# ê°œë°œ PC (RTX 4090)ì—ì„œ ìµœì í™”
python tools/onnx_optimizer.py --model model.onnx --config config.yaml

# ë°°í¬ ì„œë²„ (RTX A5000)ì—ì„œ ìž¬ìµœì í™”
python tools/onnx_optimizer.py --model model.onnx --config config.yaml
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: í´ë¼ìš°ë“œ ì¸ìŠ¤í„´ìŠ¤ë³„ ìµœì í™”
```bash
# AWS p3.2xlarge (V100) ìµœì í™”
python tools/onnx_optimizer.py --model model.onnx --config aws_config.yaml

# GCP n1-standard-4 (T4) ìµœì í™”  
python tools/onnx_optimizer.py --model model.onnx --config gcp_config.yaml
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ë°°ì¹˜ vs ì‹¤ì‹œê°„ ìµœì í™”
```bash
# ì‹¤ì‹œê°„ ì¶”ë¡  ìµœì í™” (ë¹ ë¥¸ ì´ˆê¸°í™” ì¤‘ì‹œ)
python tools/onnx_optimizer.py --model model.onnx --quick

# ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” (ìµœëŒ€ ì„±ëŠ¥ ì¤‘ì‹œ)
python tools/onnx_optimizer.py --model model.onnx --warmup 100 --runs 200
```

## ðŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²°ì±…

#### 1. GPU ì¸ì‹ ì‹¤íŒ¨
```
Error: CUDA GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
```
**í•´ê²°ì±…:**
```bash
# CUDA í™˜ê²½ í™•ì¸
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
```

#### 2. ONNXRuntime CUDA Provider ì‹¤íŒ¨
```
Error: CUDA Provider í™œì„±í™” ì‹¤íŒ¨
```
**í•´ê²°ì±…:**
```bash
# ONNXRuntime GPU ë²„ì „ ì„¤ì¹˜
pip install onnxruntime-gpu==1.18.0 \
    --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/

# CUDA ê²½ë¡œ í™•ì¸
export CUDA_PATH=/usr/local/cuda-12.1
```

#### 3. ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜
```
Error: GPU memory allocation failed
```
**í•´ê²°ì±…:**
- `gpu_mem_limit_gb` ê°’ì„ ë‚®ì¶¤ (4GBë¡œ ì‹œìž‘)
- ë‹¤ë¥¸ GPU í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
- `--quick` ëª¨ë“œë¡œ ê°€ë²¼ìš´ í…ŒìŠ¤íŠ¸

#### 4. ì„±ëŠ¥ì´ ì˜ˆìƒë³´ë‹¤ ë‚®ìŒ
```
ì¸¡ì • ê²°ê³¼ê°€ ê³µì‹ ë²¤ì¹˜ë§ˆí¬ë³´ë‹¤ ë‚®ìŒ
```
**ì›ì¸ ë¶„ì„:**
- GPU í´ëŸ­ ë‹¤ìš´ìŠ¤ì¼€ì¼ë§ í™•ì¸
- ì—´ì  ì“°ë¡œí‹€ë§ í™•ì¸  
- ë™ì‹œ ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤ í™•ì¸
- ì „ë ¥ ì œí•œ ì„¤ì • í™•ì¸

## ðŸ’¡ ìµœì í™” ì›ë¦¬ ì‹¬í™”

### cuDNN ì•Œê³ ë¦¬ì¦˜ ìž‘ë™ ë©”ì»¤ë‹ˆì¦˜

#### HEURISTIC ì•Œê³ ë¦¬ì¦˜ ì„ íƒ ë¡œì§
```cpp
// cuDNN ë‚´ë¶€ ì˜ì‚¬ì½”ë“œ
if (input_height * input_width > 256*256) {
    if (filter_size <= 3) {
        return WINOGRAD_NONFUSED;  // í° ìž…ë ¥ + ìž‘ì€ í•„í„°
    } else {
        return IMPLICIT_GEMM;      // í° ìž…ë ¥ + í° í•„í„°
    }
} else {
    return DIRECT_CONVOLUTION;     // ìž‘ì€ ìž…ë ¥
}

// GPU ë©”ëª¨ë¦¬ ëŒ€ì—­í­ ê³ ë ¤
if (memory_bandwidth_limited) {
    prefer_memory_efficient_algorithms();
} else {
    prefer_compute_intensive_algorithms();
}
```

#### EXHAUSTIVE vs HEURISTIC ì„±ëŠ¥ ì°¨ì´ ì›ì¸

**EXHAUSTIVEê°€ ëŠë¦° ì´ìœ  (RTX A5000 ê¸°ì¤€):**
1. **ìž˜ëª»ëœ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ**: ë²¤ì¹˜ë§ˆí‚¹ ì¡°ê±´ê³¼ ì‹¤ì œ ì¡°ê±´ì˜ ì°¨ì´
2. **ë©”ëª¨ë¦¬ ì ‘ê·¼ íŒ¨í„´**: ì„ íƒëœ ì•Œê³ ë¦¬ì¦˜ì´ A5000ì˜ ë©”ëª¨ë¦¬ ê³„ì¸µêµ¬ì¡°ì— ë¶€ì í•©
3. **ì˜¤ë²„í—¤ë“œ**: ë³µìž¡í•œ ì•Œê³ ë¦¬ì¦˜ì˜ ì¶”ê°€ ì—°ì‚° ë¹„ìš©
4. **ìºì‹œ ë¯¸ìŠ¤**: ë” ë§Žì€ ë©”ëª¨ë¦¬ ì ‘ê·¼ìœ¼ë¡œ ì¸í•œ ìºì‹œ íš¨ìœ¨ì„± ì €í•˜

**HEURISTICì´ ë¹ ë¥¸ ì´ìœ :**
1. **ì‹¤ìš©ì  ì„ íƒ**: ì‹¤ì œ ì‚¬ìš© íŒ¨í„´ì— ìµœì í™”ëœ ê²½í—˜ì  ê·œì¹™
2. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: A5000ì˜ ë©”ëª¨ë¦¬ íŠ¹ì„±ì— ë§žëŠ” ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
3. **ë‹¨ìˆœì„±**: ë¶ˆí•„ìš”í•œ ë³µìž¡ì„± ì œê±°
4. **ìºì‹œ ì¹œí™”ì **: íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ì ‘ê·¼ íŒ¨í„´

### GPUë³„ ìµœì í™” íŒ¨í„´

#### ê³ ì„±ëŠ¥ GPU (RTX 4090, A100)
- **íŠ¹ì§•**: ë†’ì€ ë©”ëª¨ë¦¬ ëŒ€ì—­í­, ë§Žì€ CUDA ì½”ì–´
- **ê¶Œìž¥**: HEURISTIC + ëŒ€ìš©ëŸ‰ ë©”ëª¨ë¦¬ + ë³„ë„ ìŠ¤íŠ¸ë¦¼
- **ê¸°ëŒ€ ì„±ëŠ¥**: 10-12ms (80-100 FPS)

#### ì¤‘ê¸‰ GPU (RTX 3080, A5000)  
- **íŠ¹ì§•**: ì¤‘ê°„ ë©”ëª¨ë¦¬ ëŒ€ì—­í­, ì ë‹¹í•œ CUDA ì½”ì–´
- **ê¶Œìž¥**: HEURISTIC + ì¤‘ê°„ ë©”ëª¨ë¦¬ + ìµœì í™” í™œì„±í™”
- **ê¸°ëŒ€ ì„±ëŠ¥**: 13-15ms (65-75 FPS)

#### ì—”íŠ¸ë¦¬ GPU (RTX 3060, T4)
- **íŠ¹ì§•**: ì œí•œëœ ë©”ëª¨ë¦¬, ì ì€ CUDA ì½”ì–´
- **ê¶Œìž¥**: DEFAULT + ì ì€ ë©”ëª¨ë¦¬ + ë³´ìˆ˜ì  ì„¤ì •
- **ê¸°ëŒ€ ì„±ëŠ¥**: 20-25ms (40-50 FPS)

## ðŸŽ¯ í”„ë¡œë•ì…˜ ë°°í¬ ê°€ì´ë“œ

### 1. ê°œë°œ ë‹¨ê³„
```bash
# ê°œë°œ í™˜ê²½ì—ì„œ ì´ˆê¸° ìµœì í™”
python tools/onnx_optimizer.py --model model.onnx --config dev_config.yaml
```

### 2. ìŠ¤í…Œì´ì§• ë‹¨ê³„
```bash
# ìŠ¤í…Œì´ì§• ì„œë²„ì—ì„œ ìž¬ìµœì í™”
python tools/onnx_optimizer.py --model model.onnx --config staging_config.yaml --warmup 50 --runs 100
```

### 3. í”„ë¡œë•ì…˜ ë°°í¬
```bash
# í”„ë¡œë•ì…˜ ì„œë²„ì—ì„œ ìµœì¢… ìµœì í™”
python tools/onnx_optimizer.py --model model.onnx --config prod_config.yaml --output prod_optimization_report.md
```

### 4. ì§€ì†ì  ëª¨ë‹ˆí„°ë§
```python
# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì½”ë“œ ì˜ˆì‹œ
def monitor_inference_performance():
    times = []
    for _ in range(100):
        start = time.time()
        result = model.run(input_data)
        times.append(time.time() - start)
    
    avg_fps = 1.0 / np.mean(times)
    
    # ì„±ëŠ¥ ì €í•˜ ê°ì§€
    if avg_fps < expected_fps * 0.9:  # 10% ì´ìƒ ì €í•˜
        logger.warning("ì„±ëŠ¥ ì €í•˜ ê°ì§€ - ìž¬ìµœì í™” í•„ìš”")
        # ìžë™ ìž¬ìµœì í™” íŠ¸ë¦¬ê±°
```

## ðŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ìƒˆë¡œìš´ GPU í™˜ê²½ ë°°í¬ì‹œ
- [ ] `nvidia-smi`ë¡œ GPU í™•ì¸
- [ ] CUDA/cuDNN ë²„ì „ í˜¸í™˜ì„± í™•ì¸
- [ ] ONNXRuntime GPU ë²„ì „ ì„¤ì¹˜
- [ ] ìµœì í™” ë„êµ¬ ì‹¤í–‰
- [ ] ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„± í™•ì¸
- [ ] config.yaml ë°±ì—… ë° ì ìš©
- [ ] ì‹¤ì œ ì›Œí¬ë¡œë“œë¡œ ê²€ì¦

### ì„±ëŠ¥ ë¬¸ì œ ë°œìƒì‹œ
- [ ] ìµœì í™” ë„êµ¬ ìž¬ì‹¤í–‰
- [ ] GPU ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
- [ ] ì—´ì  ì“°ë¡œí‹€ë§ í™•ì¸
- [ ] ë™ì‹œ ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤ í™•ì¸
- [ ] ONNXRuntime ë²„ì „ í™•ì¸

## ðŸ“š ì°¸ê³  ìžë£Œ

- [ONNXRuntime CUDA Provider ë¬¸ì„œ](https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html)
- [cuDNN Algorithm Selection Guide](https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html)
- [RTMO ê³µì‹ ë²¤ì¹˜ë§ˆí¬](https://github.com/open-mmlab/mmpose/tree/main/projects/rtmo)

---

**ìžë™ ìƒì„±ëœ ë¬¸ì„œ** - `tools/onnx_optimizer.py`ë¡œ GPUë³„ ìµœì  ì„¤ì •ì„ ìžë™ìœ¼ë¡œ ì°¾ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.