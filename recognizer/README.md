# ëª¨ë“ˆí™”ëœ í­ë ¥ íƒì§€ ì‹œìŠ¤í…œ

4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì„ í†µí•œ íš¨ìœ¨ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ í­ë ¥ íƒì§€ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

```bash
# ê¸°ë³¸ ì¶”ë¡ 
python recognizer/main.py --mode inference --input video.mp4

# PKL ìƒì„± + ì‹œê°í™” (ì„±ëŠ¥ í‰ê°€ í¬í•¨)
python recognizer/main.py --mode inference --input video.mp4 --enable_evaluation --enable_visualization

# í”„ë¦¬ì…‹ ì‚¬ìš©
python recognizer/main.py --config configs/presets/inference_with_evaluation.yaml --input video.mp4
```

**ìì„¸í•œ ì‚¬ìš©ë²•ì€ [USAGE.md](USAGE.md)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.**

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸
1. **í¬ì¦ˆ ì¶”ì • (Pose Estimation)** - RTMO ëª¨ë¸ì„ í†µí•œ ì‹¤ì‹œê°„ í¬ì¦ˆ ê²€ì¶œ
2. **ê°ì²´ ì¶”ì  (Object Tracking)** - ByteTrackerë¥¼ í†µí•œ ë‹¤ì¤‘ ê°ì²´ ì¶”ì 
3. **ë³µí•© ì ìˆ˜ ê³„ì‚° (Composite Scoring)** - 5ì˜ì—­ ê¸°ë°˜ ë³µí•©ì ìˆ˜ ê³„ì‚°
4. **í–‰ë™ ë¶„ë¥˜ (Action Classification)** - ST-GCN++ë¥¼ í†µí•œ í­ë ¥/ë¹„í­ë ¥ ë¶„ë¥˜

### ì£¼ìš” íŠ¹ì§•
- âœ… **ëª¨ë“ˆí™”ëœ ì„¤ê³„**: ê° ë‹¨ê³„ë³„ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ êµ¬ì„±
- âœ… **íŒ©í† ë¦¬ íŒ¨í„´**: ì‰¬ìš´ ëª¨ë¸ êµì²´ ë° í™•ì¥
- âœ… **í‘œì¤€í™”ëœ API**: ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤ ì œê³µ
- âœ… **ì‹¤ì‹œê°„ ì²˜ë¦¬**: RTSP ìŠ¤íŠ¸ë¦¼ ë° ì›¹ìº  ì§€ì›
- âœ… **ë°°ì¹˜ ì²˜ë¦¬**: ëŒ€ìš©ëŸ‰ ë¹„ë””ì˜¤ ì²˜ë¦¬ ìµœì í™”
- âœ… **ì‹œê°í™” ë„êµ¬**: ê²°ê³¼ ë¶„ì„ ë° ê²€ì¦ ë„êµ¬ ì œê³µ

## ğŸ“¦ ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­
- Python 3.8+
- PyTorch 1.11+
- CUDA 11.0+ (GPU ì‚¬ìš© ì‹œ)
- MMPose, MMAction2

### ì˜ì¡´ì„± ì„¤ì¹˜
```bash
# ê¸°ë³¸ ì˜ì¡´ì„±
pip install torch torchvision opencv-python numpy matplotlib seaborn pyyaml

# MMPose ì„¤ì¹˜ (í¬ì¦ˆ ì¶”ì •)
cd mmpose
pip install -e .

# MMAction2 ì„¤ì¹˜ (í–‰ë™ ë¶„ë¥˜)
cd mmaction2  
pip install -e .
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from recognizer import factory
from recognizer.utils.data_structure import *
from recognizer.pipelines.unified_pipeline import *

# ì„¤ì • ìƒì„±
pose_config = PoseEstimationConfig(
    model_name='rtmo',
    config_file='path/to/rtmo_config.py',
    model_path='path/to/rtmo_model.pth'
)

# íŒŒì´í”„ë¼ì¸ ì„¤ì •
pipeline_config = PipelineConfig(
    pose_config=pose_config,
    tracking_config=TrackingConfig(tracker_name='bytetrack'),
    scoring_config=ScoringConfig(scorer_name='region_based'),
    classification_config=ActionClassificationConfig(model_name='stgcn')
)

# í†µí•© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
with UnifiedPipeline(pipeline_config) as pipeline:
    result = pipeline.process_video('input_video.mp4')
    print(f"ì²˜ë¦¬ ì™„ë£Œ: {result.avg_fps:.1f} FPS")
```

### 2. ì„¤ì • íŒŒì¼ ì‚¬ìš©

```python
import yaml
from recognizer.examples.config_usage import *

# YAML ì„¤ì • ë¡œë“œ
config = yaml.safe_load(open('configs/default_config.yaml'))
pose_config, tracking_config, scoring_config, classification_config = create_configs_from_yaml(config)

# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
pipeline_config = PipelineConfig(pose_config, tracking_config, scoring_config, classification_config)
```

### 3. ì‹¤ì‹œê°„ ì²˜ë¦¬

```python
from recognizer.pipelines.inference_pipeline import *

# ì‹¤ì‹œê°„ ì„¤ì •
realtime_config = RealtimeConfig(
    pose_config=pose_config,
    # ... ê¸°íƒ€ ì„¤ì •
    target_fps=30.0,
    alert_threshold=0.7
)

# ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸
with InferencePipeline(realtime_config) as pipeline:
    # ì•Œë¦¼ ì½œë°± ë“±ë¡
    pipeline.add_alert_callback(lambda alert: print(f"[ì•Œë¦¼] {alert.alert_type}"))
    
    # ì›¹ìº ì—ì„œ ì‹¤ì‹œê°„ ì²˜ë¦¬
    pipeline.start_realtime_processing(source=0)
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
recognizer/
â”œâ”€â”€ __init__.py                    # ë©”ì¸ ëª¨ë“ˆ ë° íŒ©í† ë¦¬ ì´ˆê¸°í™”
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_structure.py         # í‘œì¤€ ë°ì´í„° êµ¬ì¡°
â”‚   â””â”€â”€ factory.py                # ëª¨ë“ˆ íŒ©í† ë¦¬ íŒ¨í„´
â”œâ”€â”€ pose_estimation/              # í¬ì¦ˆ ì¶”ì • ëª¨ë“ˆ
â”‚   â”œâ”€â”€ base.py                   # ê¸°ë³¸ ì¶”ìƒ í´ë˜ìŠ¤
â”‚   â””â”€â”€ rtmo/                     # RTMO êµ¬í˜„
â”œâ”€â”€ tracking/                     # ê°ì²´ ì¶”ì  ëª¨ë“ˆ  
â”‚   â”œâ”€â”€ base.py                   # ê¸°ë³¸ ì¶”ìƒ í´ë˜ìŠ¤
â”‚   â””â”€â”€ bytetrack/                # ByteTracker êµ¬í˜„
â”œâ”€â”€ scoring/                      # ë³µí•©ì ìˆ˜ ê³„ì‚° ëª¨ë“ˆ
â”‚   â”œâ”€â”€ base.py                   # ê¸°ë³¸ ì¶”ìƒ í´ë˜ìŠ¤
â”‚   â””â”€â”€ region_based/             # ì˜ì—­ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
â”œâ”€â”€ action_classification/        # í–‰ë™ ë¶„ë¥˜ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ base.py                   # ê¸°ë³¸ ì¶”ìƒ í´ë˜ìŠ¤
â”‚   â””â”€â”€ stgcn/                    # ST-GCN++ êµ¬í˜„
â”œâ”€â”€ pipelines/                    # í†µí•© íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ unified_pipeline.py       # ì „ì²´ 4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ annotation_pipeline.py    # ì–´ë…¸í…Œì´ì…˜ êµ¬ì¶•ìš©
â”‚   â””â”€â”€ inference_pipeline.py     # ì‹¤ì‹œê°„ ì¶”ë¡ ìš©
â”œâ”€â”€ visualization/                # ì‹œê°í™” ë„êµ¬
â”‚   â”œâ”€â”€ pose_visualizer.py        # í¬ì¦ˆ ì‹œê°í™”
â”‚   â”œâ”€â”€ result_visualizer.py      # ê²°ê³¼ ë¶„ì„ ì‹œê°í™”
â”‚   â””â”€â”€ annotation_visualizer.py  # ì–´ë…¸í…Œì´ì…˜ ë„êµ¬
â”œâ”€â”€ examples/                     # ì‚¬ìš© ì˜ˆì œ
â”‚   â”œâ”€â”€ basic_usage.py            # ê¸°ë³¸ ì‚¬ìš©ë²•
â”‚   â””â”€â”€ config_usage.py           # ì„¤ì • íŒŒì¼ ì‚¬ìš©ë²•
â””â”€â”€ configs/                      # ì„¤ì • íŒŒì¼
    â””â”€â”€ default_config.yaml       # ê¸°ë³¸ ì„¤ì •
```

## ğŸ“Š ëª¨ë“ˆ ìƒì„¸

### í¬ì¦ˆ ì¶”ì • (Pose Estimation)
- **RTMO**: ì‹¤ì‹œê°„ ë‹¤ì¤‘ ê°ì²´ í¬ì¦ˆ ê²€ì¶œ
- **ì§€ì› í˜•ì‹**: ì´ë¯¸ì§€, ë¹„ë””ì˜¤, ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼
- **ì¶œë ¥**: 17ê°œ í‚¤í¬ì¸íŠ¸ + ë°”ìš´ë”© ë°•ìŠ¤

### ê°ì²´ ì¶”ì  (Tracking)  
- **ByteTracker**: ê³ ì„±ëŠ¥ ë‹¤ì¤‘ ê°ì²´ ì¶”ì 
- **íŠ¹ì§•**: Kalman í•„í„° ê¸°ë°˜, ID ìœ ì§€
- **ì¶œë ¥**: íŠ¸ë™ IDê°€ í• ë‹¹ëœ í¬ì¦ˆ ì‹œí€€ìŠ¤

### ë³µí•©ì ìˆ˜ ê³„ì‚° (Scoring)
- **5ì˜ì—­ ë¶„í• **: í™”ë©´ì„ 5ê°œ ì˜ì—­ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„
- **5ê°€ì§€ ì ìˆ˜**: ì›€ì§ì„, ìœ„ì¹˜, ìƒí˜¸ì‘ìš©, ì‹œê°„ì¼ê´€ì„±, ì§€ì†ì„±
- **ê°€ì¤‘ í•©ì‚°**: ì„¤ì • ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜ë¡œ ìµœì¢… ì ìˆ˜ ê³„ì‚°

### í–‰ë™ ë¶„ë¥˜ (Classification)
- **ST-GCN++**: ìŠ¤ì¼ˆë ˆí†¤ ê¸°ë°˜ í–‰ë™ ì¸ì‹
- **ìŠ¬ë¼ì´ë”© ìœˆë„ìš°**: 100 í”„ë ˆì„ ë‹¨ìœ„ ë¶„ì„
- **í´ë˜ìŠ¤**: Fight/NonFight (í™•ì¥ ê°€ëŠ¥)

## ğŸ”§ í™•ì¥ ë°©ë²•

### ìƒˆë¡œìš´ í¬ì¦ˆ ì¶”ì • ëª¨ë¸ ì¶”ê°€

```python
from recognizer.pose_estimation.base import BasePoseEstimator

class NewPoseEstimator(BasePoseEstimator):
    def initialize_model(self):
        # ëª¨ë¸ ì´ˆê¸°í™” ë¡œì§
        pass
    
    def extract_poses(self, image, frame_idx):
        # í¬ì¦ˆ ì¶”ì • ë¡œì§
        pass

# íŒ©í† ë¦¬ì— ë“±ë¡
factory.register_pose_estimator('new_model', NewPoseEstimator)
```

### ìƒˆë¡œìš´ íŠ¸ë˜ì»¤ ì¶”ê°€

```python
# MMTracking ê¸°ë°˜ íŠ¸ë˜ì»¤ ì‚¬ìš© (ê¶Œì¥)
from recognizer.tracking.mmtracking_adapter import MMTrackingAdapter

# ê¸°ë³¸ ì œê³µ íŠ¸ë˜ì»¤ë“¤: 'bytetrack', 'deepsort', 'sort'
tracker_config = TrackingConfig(
    tracker_name='bytetrack',
    device='cuda:0'
)

tracker = MMTrackingAdapter(tracker_config)
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### GPU ê°€ì†
```python
# GPU ì„¤ì •
config.device = 'cuda:0'
config.enable_gpu = True
config.batch_size = 4  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
```

### ì‹¤ì‹œê°„ ìµœì í™”
```python
# ì‹¤ì‹œê°„ ì„±ëŠ¥ í–¥ìƒ
realtime_config.skip_frames = 2  # í”„ë ˆì„ ê±´ë„ˆë›°ê¸°
realtime_config.resize_input = (480, 480)  # ì…ë ¥ í¬ê¸° ì¶•ì†Œ
realtime_config.inference_stride = 50  # ì¶”ë¡  ê°„ê²© ì¦ê°€
```

### ë©”ëª¨ë¦¬ ìµœì í™”
```python
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
config.save_intermediate_results = False
config.max_queue_size = 50
```

## ğŸ“Š ê²°ê³¼ ë¶„ì„

### ì‹œê°í™” ë„êµ¬
```python
from recognizer.visualization import *

# í¬ì¦ˆ ì‹œê°í™”
pose_viz = PoseVisualizer()
pose_viz.visualize_video_poses('input.mp4', poses, 'output_poses.mp4')

# ê²°ê³¼ ë¶„ì„
result_viz = ResultVisualizer()
result_viz.visualize_classification_results(results, 'analysis.png')
result_viz.create_timeline_visualization(results, 'timeline.png')
```

### ì„±ëŠ¥ ë©”íŠ¸ë¦­
- **ì²˜ë¦¬ ì†ë„**: FPS, ë‹¨ê³„ë³„ ì²˜ë¦¬ ì‹œê°„
- **ì •í™•ë„**: ë¶„ë¥˜ ì •í™•ë„, ì‹ ë¢°ë„ ë¶„í¬
- **ìì› ì‚¬ìš©ëŸ‰**: GPU/CPU ì‚¬ìš©ë¥ , ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ
1. **CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±**: ë°°ì¹˜ í¬ê¸° ê°ì†Œ, ì…ë ¥ í¬ê¸° ì¶•ì†Œ
2. **ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨**: ê²½ë¡œ í™•ì¸, ì˜ì¡´ì„± ì„¤ì¹˜ í™•ì¸
3. **ë‚®ì€ FPS**: GPU ì‚¬ìš©, í”„ë ˆì„ ê±´ë„ˆë›°ê¸° í™œì„±í™”

### ë””ë²„ê·¸ ëª¨ë“œ
```python
config.debug.verbose = True
config.debug.save_intermediate = True  # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
config.debug.profile_performance = True  # ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
```

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” ê¸°ì¡´ rtmo_gcn_pipelineì˜ ì½”ë“œë¥¼ ìƒˆë¡œìš´ ëª¨ë“ˆí™” êµ¬ì¡°ì— ë§ê²Œ ì¬êµ¬ì„±í•œ ê²ƒì…ë‹ˆë‹¤.

## ğŸ¤ ê¸°ì—¬ ë°©ë²•

1. ìƒˆë¡œìš´ ëª¨ë¸ êµ¬í˜„ ì‹œ í•´ë‹¹ ëª¨ë“ˆì˜ base í´ë˜ìŠ¤ ìƒì†
2. í‘œì¤€ ë°ì´í„° êµ¬ì¡° ì‚¬ìš©
3. íŒ©í† ë¦¬ íŒ¨í„´ì„ í†µí•œ ë“±ë¡
4. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ìˆê±°ë‚˜ ê¸°ëŠ¥ ìš”ì²­ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.