# Recognizer ì‚¬ìš©ì ê°€ì´ë“œ

**ì™„ì „ ëª¨ë“ˆí™”ëœ ë¹„ë””ì˜¤ ë¶„ì„ ì‹œìŠ¤í…œ ìƒì„¸ ì‚¬ìš©ë²•**

## ğŸ“š ëª©ì°¨

1. [ë¹ ë¥¸ ì‹œì‘](#ë¹ ë¥¸-ì‹œì‘)
2. [ëª¨ë“œë³„ ìƒì„¸ ê°€ì´ë“œ](#ëª¨ë“œë³„-ìƒì„¸-ê°€ì´ë“œ)
3. [ì„¤ì • íŒŒì¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•](#ì„¤ì •-íŒŒì¼-ì»¤ìŠ¤í„°ë§ˆì´ì§•)
4. [ê³ ê¸‰ ì›Œí¬í”Œë¡œìš°](#ê³ ê¸‰-ì›Œí¬í”Œë¡œìš°)
5. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì‹œìŠ¤í…œ í™•ì¸
```bash
# ëª¨ë“  ëª¨ë“œ í™•ì¸
python main.py --list-modes

# ê¸°ë³¸ ì„¤ì • í™•ì¸
python main.py --mode inference.analysis --log-level DEBUG
```

### 2. ì²« ë²ˆì§¸ ë¶„ì„
```bash
# ê¸°ë³¸ ë¶„ì„ ì‹¤í–‰
python main.py

# ê²°ê³¼ í™•ì¸
ls output/analysis/
```

## ğŸ¯ ëª¨ë“œë³„ ìƒì„¸ ê°€ì´ë“œ

### Inference ëª¨ë“œ

#### ğŸ“Š inference.analysis - ë¶„ì„ ëª¨ë“œ

**ìš©ë„**: ë¹„ë””ì˜¤ë¥¼ ì™„ì „íˆ ë¶„ì„í•˜ì—¬ JSON/PKL íŒŒì¼ ìƒì„±

**íŠ¹ì§•**:
- ì „ì²´ ë¹„ë””ì˜¤ ì™„ì „ ì²˜ë¦¬ (20ì´ˆ ì œí•œ ì—†ìŒ)
- ì‹œê°í™” ì—†ì´ ë°ì´í„°ë§Œ ìƒì„±
- ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›

**ì„¤ì • ì˜ˆì‹œ**:
```yaml
inference:
  analysis:
    input: "/path/to/video.mp4"           # ë‹¨ì¼ íŒŒì¼
    # input_dir: "/path/to/videos/"       # í´ë” ì²˜ë¦¬
    output_dir: "output/analysis"
```

**ì‹¤í–‰**:
```bash
# ë‹¨ì¼ íŒŒì¼
python main.py --mode inference.analysis

# ì»¤ìŠ¤í…€ ì„¤ì •
python main.py --config custom.yaml --mode inference.analysis
```

**ì¶œë ¥**:
```
output/analysis/
â”œâ”€â”€ json/
â”‚   â””â”€â”€ video_results.json
â””â”€â”€ pkl/
    â”œâ”€â”€ video_frame_poses.pkl
    â””â”€â”€ video_rtmo_poses.pkl
```

#### ğŸ¥ inference.realtime - ì‹¤ì‹œê°„ ëª¨ë“œ

**ìš©ë„**: ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ë° ë¼ì´ë¸Œ ë””ìŠ¤í”Œë ˆì´

**íŠ¹ì§•**:
- ì‹¤ì‹œê°„ ì˜¤ë²„ë ˆì´ í‘œì‹œ
- ì„ íƒì  ê²°ê³¼ ë¹„ë””ì˜¤ ì €ì¥
- í‚¤ë³´ë“œ ì¸í„°ë™ì…˜ ì§€ì›

**ì„¤ì • ì˜ˆì‹œ**:
```yaml
inference:
  realtime:
    input: "/path/to/video.mp4"
    save_output: true                     # ë¹„ë””ì˜¤ ì €ì¥ ì—¬ë¶€
    output_path: "output/realtime.mp4"
    display_width: 1280
    display_height: 720
```

**ì‹¤í–‰**:
```bash
python main.py --mode inference.realtime
```

**í‚¤ë³´ë“œ ì¡°ì‘**:
- `q`: ì¢…ë£Œ
- `space`: ì¼ì‹œì •ì§€/ì¬ìƒ
- `s`: ìŠ¤í¬ë¦°ìƒ· ì €ì¥

#### ğŸ¨ inference.visualize - ì‹œê°í™” ëª¨ë“œ

**ìš©ë„**: ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ë¥¼ ê³ í’ˆì§ˆ ì˜¤ë²„ë ˆì´ë¡œ ì‹œê°í™”

**íŠ¹ì§•**:
- PKL íŒŒì¼ ê¸°ë°˜ ì •í™•í•œ ì¬í˜„
- ê³ í’ˆì§ˆ ì˜¤ë²„ë ˆì´ ìƒì„±
- ì‹¤ì‹œê°„ í‘œì‹œ ë˜ëŠ” íŒŒì¼ ì €ì¥

**ì„¤ì • ì˜ˆì‹œ**:
```yaml
inference:
  visualize:
    results_dir: "output/analysis"        # ë¶„ì„ ê²°ê³¼ ë””ë ‰í† ë¦¬
    video_file: "/path/to/video.mp4"      # ì›ë³¸ ë¹„ë””ì˜¤
    # video_dir: "/path/to/videos/"       # í´ë” ì‹œê°í™”
    save_mode: true                       # true: ì €ì¥, false: ì‹¤ì‹œê°„ í‘œì‹œ
    save_dir: "output/overlay"
```

**ì‹¤í–‰**:
```bash
# ì‹¤ì‹œê°„ í‘œì‹œ
python main.py --mode inference.visualize

# íŒŒì¼ ì €ì¥ (config.yamlì—ì„œ save_mode: true ì„¤ì •)
python main.py --mode inference.visualize
```

### Annotation ëª¨ë“œ

#### ğŸ¯ annotation.stage1 - í¬ì¦ˆ ì¶”ì •

**ìš©ë„**: ë¹„ë””ì˜¤ì—ì„œ RTMO í¬ì¦ˆ ì¶”ì •ë§Œ ìˆ˜í–‰

**íŠ¹ì§•**:
- 17ê°œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
- ë‹¤ì¤‘ ê°ì²´ ì§€ì›
- ì›ì‹œ í¬ì¦ˆ ë°ì´í„° ì €ì¥

**ì„¤ì • ì˜ˆì‹œ**:
```yaml
annotation:
  stage1:
    input_dir: "/workspace/raw_videos"
    output_dir: "output/stage1_poses"
```

**ì‹¤í–‰**:
```bash
python main.py --mode annotation.stage1
```

**ì¶œë ¥**:
```
output/stage1_poses/
â”œâ”€â”€ video1_poses.pkl
â”œâ”€â”€ video2_poses.pkl
â””â”€â”€ ...
```

#### ğŸ”— annotation.stage2 - íŠ¸ë˜í‚¹ ë° ì •ë ¬

**ìš©ë„**: Stage1 ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°ì²´ ì¶”ì  ë° ì •ë ¬

**íŠ¹ì§•**:
- ByteTrack ê¸°ë°˜ ì¶”ì 
- ë³µí•© ì ìˆ˜ ê³„ì‚°
- í•˜ì´ë¸Œë¦¬ë“œ ë§¤ì¹­ (IoU + í‚¤í¬ì¸íŠ¸)

**ì„¤ì • ì˜ˆì‹œ**:
```yaml
annotation:
  stage2:
    poses_dir: "output/stage1_poses"      # Stage1 ê²°ê³¼
    output_dir: "output/stage2_tracking"
```

**ì‹¤í–‰**:
```bash
python main.py --mode annotation.stage2
```

**ì¶œë ¥**:
```
output/stage2_tracking/
â”œâ”€â”€ video1_tracking.pkl
â”œâ”€â”€ video2_tracking.pkl
â””â”€â”€ ...
```

#### ğŸ—ƒï¸ annotation.stage3 - ë°ì´í„°ì…‹ í†µí•©

**ìš©ë„**: ê°œë³„ ë¹„ë””ì˜¤ ê²°ê³¼ë¥¼ í•™ìŠµìš© ë°ì´í„°ì…‹ìœ¼ë¡œ í†µí•©

**íŠ¹ì§•**:
- train/val/test ë¶„í•  (7:1.5:1.5)
- ë©”íƒ€ë°ì´í„° ìƒì„±
- ëª¨ë¸ í•™ìŠµ í˜•ì‹ ë³€í™˜

**ì„¤ì • ì˜ˆì‹œ**:
```yaml
annotation:
  stage3:
    tracking_dir: "output/stage2_tracking"
    output_dir: "output/stage3_dataset"
    split_ratios:
      train: 0.7
      val: 0.15
      test: 0.15
```

**ì‹¤í–‰**:
```bash
python main.py --mode annotation.stage3
```

**ì¶œë ¥**:
```
output/stage3_dataset/
â”œâ”€â”€ train.pkl
â”œâ”€â”€ val.pkl
â”œâ”€â”€ test.pkl
â””â”€â”€ metadata.json
```

#### ğŸ‘ï¸ annotation.visualize - ì–´ë…¸í…Œì´ì…˜ ì‹œê°í™”

**ìš©ë„**: ê° stageë³„ ì¤‘ê°„ ê²°ê³¼ ì‹œê°í™”

**íŠ¹ì§•**:
- stageë³„ ë§ì¶¤ ì‹œê°í™”
- ë””ë²„ê¹… ë° ê²€ì¦ ìš©ë„
- ì‹¤ì‹œê°„ ë˜ëŠ” ì €ì¥ ëª¨ë“œ

**ì„¤ì • ì˜ˆì‹œ**:
```yaml
annotation:
  visualize:
    stage: "stage2"                       # stage1, stage2, stage3
    results_dir: "output/stage2_tracking"
    video_dir: "/workspace/raw_videos"
    save_mode: false
    save_dir: "output/annotation_overlay"
```

**ì‹¤í–‰**:
```bash
# Stage2 ê²°ê³¼ ì‹œê°í™”
python main.py --mode annotation.visualize

# Stage1 ê²°ê³¼ ì‹œê°í™” (config.yamlì—ì„œ stage: "stage1" ì„¤ì •)
python main.py --mode annotation.visualize
```

## âš™ï¸ ì„¤ì • íŒŒì¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ê¸°ë³¸ ì„¤ì • êµ¬ì¡°

```yaml
# ê¸°ë³¸ ì‹¤í–‰ ëª¨ë“œ
mode: "inference.analysis"

# ì¶”ë¡  ëª¨ë“œ ì„¤ì •
inference:
  analysis: {...}
  realtime: {...}
  visualize: {...}

# ì–´ë…¸í…Œì´ì…˜ ëª¨ë“œ ì„¤ì •  
annotation:
  stage1: {...}
  stage2: {...}
  stage3: {...}
  visualize: {...}

# ëª¨ë¸ ì„¤ì • (ëª¨ë“  ëª¨ë“œ ê³µí†µ)
models:
  pose_estimation: {...}
  tracking: {...}
  scoring: {...}
  action_classification: {...}

# ì„±ëŠ¥ ì„¤ì •
performance:
  device: "cuda:0"
  window_size: 100
  window_stride: 50
  batch_size: 8
```

### ëª¨ë¸ ì„¸ë¶€ ì„¤ì •

```yaml
models:
  pose_estimation:
    model_name: "rtmo"
    config_file: "/workspace/mmpose/configs/body_2d_keypoint/rtmo/body7/rtmo-m_16xb16-600e_body7-640x640.py"
    checkpoint_path: "/workspace/mmpose/checkpoints/rtmo-m_16xb16-600e_body7-640x640-39e78cc4_20231211.pth"
    device: "cuda:0"
    score_threshold: 0.2
    input_size: [640, 640]

  tracking:
    tracker_name: "bytetrack"
    frame_rate: 30
    track_thresh: 0.2
    track_buffer: 120
    match_thresh: 0.5

  action_classification:
    model_name: "stgcn"
    config_file: "/workspace/mmaction2/configs/skeleton/stgcnpp/stgcnpp_enhanced_fight_detection_stable.py"
    checkpoint_path: "/workspace/mmaction2/work_dirs/stgcnpp-bone-ntu60_rtmo-m_RWF2000plus_stable/best_acc_top1_epoch_14.pth"
    device: "cuda:0"
    window_size: 100
    class_names: ["NonFight", "Fight"]
    confidence_threshold: 0.4
```

### ì„±ëŠ¥ ìµœì í™” ì„¤ì •

```yaml
performance:
  device: "cuda:0"
  window_size: 100                 # ë¶„ë¥˜ ìœˆë„ìš° í¬ê¸°
  window_stride: 50                # ìœˆë„ìš° ê°„ê²©
  batch_size: 8                    # ë°°ì¹˜ í¬ê¸°
  
  # ë©”ëª¨ë¦¬ ê´€ë¦¬
  max_cache_size: 1000
  gc_interval: 100
  enable_garbage_collection: true

# ì˜¤ë¥˜ ì²˜ë¦¬
error_handling:
  continue_on_error: true
  max_consecutive_errors: 10
  error_recovery_strategy: "skip"
```

## ğŸ”„ ê³ ê¸‰ ì›Œí¬í”Œë¡œìš°

### 1. ì™„ì „í•œ ë¶„ì„ íŒŒì´í”„ë¼ì¸

```bash
#!/bin/bash
# complete_analysis.sh

echo "=== 1ë‹¨ê³„: ë¶„ì„ ìˆ˜í–‰ ==="
python main.py --mode inference.analysis

echo "=== 2ë‹¨ê³„: ê²°ê³¼ ì‹œê°í™” ==="
python main.py --mode inference.visualize

echo "=== ë¶„ì„ ì™„ë£Œ ==="
ls -la output/analysis/
ls -la output/overlay/
```

### 2. ì–´ë…¸í…Œì´ì…˜ íŒŒì´í”„ë¼ì¸

```bash
#!/bin/bash
# annotation_pipeline.sh

echo "=== Stage 1: í¬ì¦ˆ ì¶”ì • ==="
python main.py --mode annotation.stage1

echo "=== Stage 2: íŠ¸ë˜í‚¹ ë° ì •ë ¬ ==="
python main.py --mode annotation.stage2

echo "=== Stage 3: ë°ì´í„°ì…‹ í†µí•© ==="
python main.py --mode annotation.stage3

echo "=== ê²°ê³¼ í™•ì¸ ==="
python main.py --mode annotation.visualize

echo "=== ì–´ë…¸í…Œì´ì…˜ ì™„ë£Œ ==="
ls -la output/stage3_dataset/
```

### 3. ë°°ì¹˜ ì²˜ë¦¬

```yaml
# batch_config.yaml
inference:
  analysis:
    input_dir: "/workspace/batch_videos"   # í´ë” ì§€ì •
    output_dir: "output/batch_analysis"

performance:
  batch_size: 4                           # ë©”ëª¨ë¦¬ ì ˆì•½
  window_stride: 25                       # ë” ì„¸ë°€í•œ ë¶„ì„
```

```bash
# ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
python main.py --config batch_config.yaml --mode inference.analysis
```

### 4. ì»¤ìŠ¤í…€ ëª¨ë¸ ì„¤ì •

```yaml
# custom_model_config.yaml
models:
  pose_estimation:
    score_threshold: 0.1               # ë” ë¯¼ê°í•œ íƒì§€
  
  action_classification:
    confidence_threshold: 0.3          # ë” ë³´ìˆ˜ì ì¸ ë¶„ë¥˜
    window_size: 150                   # ë” ê¸´ ì»¨í…ìŠ¤íŠ¸
```

## ğŸ› ï¸ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜

#### 1. ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨
```
ERROR: Failed to create pose_estimator module rtmo
```

**í•´ê²°ì±…**:
```bash
# ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ í™•ì¸
ls /workspace/mmpose/checkpoints/

# ì„¤ì •ì—ì„œ ì˜¬ë°”ë¥¸ ê²½ë¡œ ì§€ì •
# config.yamlì—ì„œ checkpoint_path ìˆ˜ì •
```

#### 2. CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```
CUDA out of memory
```

**í•´ê²°ì±…**:
```yaml
# config.yaml ìˆ˜ì •
performance:
  batch_size: 4        # 8ì—ì„œ 4ë¡œ ê°ì†Œ
  device: "cpu"        # GPU ëŒ€ì‹  CPU ì‚¬ìš©
```

#### 3. ì…ë ¥ íŒŒì¼ ì—†ìŒ
```
Input directory does not exist
```

**í•´ê²°ì±…**:
```bash
# ê²½ë¡œ í™•ì¸
ls -la /path/to/input/

# ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
# config.yamlì—ì„œ ì „ì²´ ê²½ë¡œ ì§€ì •
```

#### 4. ê¶Œí•œ ë¬¸ì œ
```
Permission denied
```

**í•´ê²°ì±…**:
```bash
# ì¶œë ¥ ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸
chmod 755 output/

# Docker ì»¨í…Œì´ë„ˆì—ì„œ ì‹¤í–‰
docker exec mmlabs bash -c "cd /workspace && python recognizer/main.py"
```

### ë””ë²„ê¹… ê°€ì´ë“œ

#### ìƒì„¸ ë¡œê·¸ í™•ì¸
```bash
python main.py --mode [MODE] --log-level DEBUG
```

#### ì„¤ì • ê²€ì¦
```bash
# ì„¤ì • íŒŒì¼ êµ¬ë¬¸ ê²€ì‚¬
python -c "import yaml; yaml.safe_load(open('config.yaml'))"

# ëª¨ë“œ ëª©ë¡ í™•ì¸
python main.py --list-modes
```

#### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```bash
# GPU ì‚¬ìš©ëŸ‰ í™•ì¸
nvidia-smi

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
htop
```

### ì„±ëŠ¥ ìµœì í™” íŒ

1. **GPU ë©”ëª¨ë¦¬ ìµœì í™”**
   - batch_size ì¡°ì •
   - window_size ê°ì†Œ
   - ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ í™œì„±í™”

2. **ì²˜ë¦¬ ì†ë„ í–¥ìƒ**
   - window_stride ì¦ê°€
   - score_threshold ì¦ê°€
   - ë³‘ë ¬ ì²˜ë¦¬ í™œìš©

3. **ì •í™•ë„ í–¥ìƒ**
   - window_size ì¦ê°€
   - score_threshold ê°ì†Œ
   - confidence_threshold ì¡°ì •

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì„¤ì¹˜ í™•ì¸
- [ ] MMPose ì„¤ì¹˜ ì™„ë£Œ
- [ ] MMAction2 ì„¤ì¹˜ ì™„ë£Œ
- [ ] CUDA í™˜ê²½ ì„¤ì •
- [ ] ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë“œ

### ì‹¤í–‰ ì „ í™•ì¸
- [ ] ì…ë ¥ íŒŒì¼/ë””ë ‰í† ë¦¬ ì¡´ì¬
- [ ] ì¶œë ¥ ë””ë ‰í† ë¦¬ ê¶Œí•œ
- [ ] GPU/CPU ìì› ì¶©ë¶„
- [ ] ì„¤ì • íŒŒì¼ êµ¬ë¬¸ ì •í™•

### ê²°ê³¼ ê²€ì¦
- [ ] JSON íŒŒì¼ ìƒì„±
- [ ] PKL íŒŒì¼ ìƒì„±  
- [ ] ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ í’ˆì§ˆ
- [ ] ë¡œê·¸ ë©”ì‹œì§€ í™•ì¸

---

**ì´ ê°€ì´ë“œë¥¼ í†µí•´ Recognizerì˜ ëª¨ë“  ê¸°ëŠ¥ì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”!** ğŸš€