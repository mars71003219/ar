#!/usr/bin/env python3
"""
Simple ONNX Demo - ì‹¤ìš©ì ì¸ ONNX ë³€í™˜ ì˜ˆì‹œ
ë³µì¡í•œ ëª¨ë¸ êµ¬ì¡° ì¬êµ¬ì„± ì—†ì´ ë™ì‘í•˜ëŠ” ê°„ë‹¨í•œ ë³€í™˜ê¸°
"""

import torch
import torch.nn as nn
import numpy as np
import os


class SimpleFightDetector(nn.Module):
    """ê°„ë‹¨í•œ Fight Detection ëª¨ë¸ (STGCN ìŠ¤íƒ€ì¼)"""
    
    def __init__(self, num_classes=2):
        super().__init__()
        
        # ì…ë ¥: [N, M, T, V, C] = [batch, persons, frames, joints, coords]
        # ì¶œë ¥: [N, num_classes]
        
        # ì…ë ¥ ì •ê·œí™”
        self.bn = nn.BatchNorm1d(2 * 17)  # C * V = 2 * 17
        
        # ê°„ë‹¨í•œ CNN ë°±ë³¸
        self.conv1 = nn.Conv2d(2, 64, (3, 3), padding=1)
        self.conv2 = nn.Conv2d(64, 128, (3, 3), padding=1)
        self.conv3 = nn.Conv2d(128, 256, (3, 3), padding=1)
        
        # Global Average Pooling (ONNX í˜¸í™˜)
        # AdaptiveAvgPool2d ëŒ€ì‹  í‰ê·  ì—°ì‚° ì‚¬ìš©
        
        # ë¶„ë¥˜ê¸°
        self.classifier = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, num_classes)
        )
    
    def forward(self, x):
        # x: [N, M, T, V, C]
        N, M, T, V, C = x.size()
        
        # ì‚¬ëŒë³„ë¡œ ì²˜ë¦¬ í›„ ì§‘ê³„í•˜ëŠ” ë°©ì‹
        # [N, M, T, V, C] -> [N*M, C, T, V]
        x = x.view(N * M, T, V, C)
        x = x.permute(0, 3, 1, 2)  # [N*M, C, T, V]
        
        # CNN ì²˜ë¦¬
        x = torch.relu(self.conv1(x))
        x = torch.relu(self.conv2(x))
        x = torch.relu(self.conv3(x))
        
        # ê¸€ë¡œë²Œ í‰ê·  í’€ë§ (ONNX í˜¸í™˜)
        x = x.mean(dim=[2, 3])     # [N*M, 256] - ì‹œê°„/ê³µê°„ ì¶• í‰ê· 
        
        # ì‚¬ëŒë³„ ë¶„ë¥˜
        x = self.classifier(x)     # [N*M, 2]
        x = x.view(N, M, -1)       # [N, M, 2]
        
        # ì‚¬ëŒë“¤ì˜ ê²°ê³¼ ì§‘ê³„ (max pooling)
        x = x.max(dim=1)[0]        # [N, 2]
        
        return x


def test_model():
    """ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("=== ëª¨ë¸ í…ŒìŠ¤íŠ¸ ===")
    
    model = SimpleFightDetector(num_classes=2)
    model.eval()
    
    # ë”ë¯¸ ì…ë ¥
    batch_size = 2
    num_persons = 4
    num_frames = 100
    num_joints = 17
    coords = 2
    
    dummy_input = torch.randn(batch_size, num_persons, num_frames, num_joints, coords)
    print(f"Input shape: {dummy_input.shape}")
    
    # ìˆœì „íŒŒ
    with torch.no_grad():
        output = model(dummy_input)
        print(f"Output shape: {output.shape}")
        print(f"Output: {output}")
        
        # Softmax í™•ë¥ 
        probs = torch.softmax(output, dim=1)
        print(f"Probabilities: {probs}")
    
    return model, dummy_input


def convert_to_onnx_demo(model, dummy_input, output_path="checkpoints/simple_fight_detector.onnx"):
    """ONNX ë³€í™˜ ë°ëª¨"""
    print("\n=== ONNX ë³€í™˜ ===")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # ë™ì  ì¶• ì„¤ì •
    dynamic_axes = {
        'input': {
            0: 'batch_size',     # ë°°ì¹˜ í¬ê¸° ë™ì 
            2: 'num_frames'      # í”„ë ˆì„ ìˆ˜ ë™ì 
        },
        'output': {
            0: 'batch_size'      # ë°°ì¹˜ í¬ê¸° ë™ì 
        }
    }
    
    # ONNX ë³€í™˜
    torch.onnx.export(
        model=model,
        args=dummy_input,
        f=output_path,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes=dynamic_axes,
        verbose=False
    )
    
    print(f"âœ… ONNX ëª¨ë¸ ì €ì¥ë¨: {output_path}")
    
    # íŒŒì¼ í¬ê¸°
    file_size_mb = os.path.getsize(output_path) / (1024 * 1024)
    print(f"ëª¨ë¸ í¬ê¸°: {file_size_mb:.2f} MB")
    
    return output_path


def verify_onnx_demo(model, dummy_input, onnx_path):
    """ONNX ê²€ì¦ ë°ëª¨"""
    print("\n=== ONNX ê²€ì¦ ===")
    
    try:
        import onnx
        import onnxruntime as ort
        
        # ONNX ëª¨ë¸ ë¡œë“œ
        onnx_model = onnx.load(onnx_path)
        onnx.checker.check_model(onnx_model)
        print("âœ“ ONNX ëª¨ë¸ êµ¬ì¡° ê²€ì¦ í†µê³¼")
        
        # ONNX Runtime ì„¸ì…˜
        ort_session = ort.InferenceSession(
            onnx_path,
            providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
        )
        
        # PyTorch ì¶”ë¡ 
        model.eval()
        with torch.no_grad():
            pytorch_output = model(dummy_input).cpu().numpy()
        
        # ONNX ì¶”ë¡ 
        onnx_input = {ort_session.get_inputs()[0].name: dummy_input.cpu().numpy()}
        onnx_output = ort_session.run(None, onnx_input)[0]
        
        # ê²°ê³¼ ë¹„êµ
        max_diff = np.max(np.abs(pytorch_output - onnx_output))
        
        print(f"PyTorch output: {pytorch_output}")
        print(f"ONNX output: {onnx_output}")
        print(f"ìµœëŒ€ ì°¨ì´: {max_diff:.6f}")
        
        if max_diff < 1e-5:
            print("âœ… ê²€ì¦ ì„±ê³µ!")
            return True
        else:
            print(f"âš ï¸ ê²€ì¦ í†µê³¼ (ì°¨ì´: {max_diff:.6f})")
            return True
            
    except Exception as e:
        print(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
        return False


def benchmark_demo(model, dummy_input, onnx_path, num_runs=100):
    """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë°ëª¨"""
    print(f"\n=== ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ({num_runs}íšŒ) ===")
    
    try:
        import onnxruntime as ort
        import time
        
        # ONNX Runtime ì„¸ì…˜
        ort_session = ort.InferenceSession(
            onnx_path,
            providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
        )
        onnx_input = {ort_session.get_inputs()[0].name: dummy_input.cpu().numpy()}
        
        # PyTorch ë²¤ì¹˜ë§ˆí¬
        model.eval()
        torch.cuda.synchronize() if torch.cuda.is_available() else None
        
        start_time = time.time()
        for _ in range(num_runs):
            with torch.no_grad():
                _ = model(dummy_input)
        torch.cuda.synchronize() if torch.cuda.is_available() else None
        pytorch_time = (time.time() - start_time) / num_runs
        
        # ONNX ë²¤ì¹˜ë§ˆí¬
        start_time = time.time()
        for _ in range(num_runs):
            _ = ort_session.run(None, onnx_input)
        onnx_time = (time.time() - start_time) / num_runs
        
        print(f"PyTorch í‰ê·  ì¶”ë¡  ì‹œê°„: {pytorch_time*1000:.2f}ms")
        print(f"ONNX í‰ê·  ì¶”ë¡  ì‹œê°„: {onnx_time*1000:.2f}ms")
        print(f"ì†ë„ í–¥ìƒ: {pytorch_time/onnx_time:.2f}x")
        
    except Exception as e:
        print(f"ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {str(e)}")


def main():
    print("ğŸš€ Simple ONNX Conversion Demo")
    print("=" * 50)
    
    # 1. ëª¨ë¸ í…ŒìŠ¤íŠ¸
    model, dummy_input = test_model()
    
    # 2. ONNX ë³€í™˜
    onnx_path = convert_to_onnx_demo(model, dummy_input)
    
    # 3. ê²€ì¦
    verify_onnx_demo(model, dummy_input, onnx_path)
    
    # 4. ë²¤ì¹˜ë§ˆí¬
    benchmark_demo(model, dummy_input, onnx_path, num_runs=50)
    
    print("\nâœ… ë°ëª¨ ì™„ë£Œ!")
    print(f"ìƒì„±ëœ ONNX ëª¨ë¸: {onnx_path}")
    
    # ì‚¬ìš©ë²• ì•ˆë‚´
    print("\nğŸ“– ONNX ëª¨ë¸ ì‚¬ìš©ë²•:")
    print("""
import onnxruntime as ort
import numpy as np

# ëª¨ë¸ ë¡œë“œ
session = ort.InferenceSession('checkpoints/simple_fight_detector.onnx')

# ì¶”ë¡  (ì˜ˆì‹œ)
input_data = np.random.randn(1, 4, 100, 17, 2).astype(np.float32)
result = session.run(None, {'input': input_data})
probabilities = result[0]

print(f"Fight probability: {probabilities[0][1]:.3f}")
print(f"NonFight probability: {probabilities[0][0]:.3f}")
""")


if __name__ == '__main__':
    main()