# Enhanced STGCN++ Configuration for Custom RTMO Fight Detection (Optimized)
# Loss ì •ì²´ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ìµœì í™”ëœ ì„¤ì •

_base_ = 'stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d.py'

# Import custom modules - ê²½ë¡œ ë¬¸ì œë¡œ ì¼ì‹œì ìœ¼ë¡œ ë¹„í™œì„±í™”
# custom_imports = dict(
#     imports=['mmaction.datasets.enhanced_pose_dataset'],
#     allow_failed_imports=False
# )

# ============================================================================
# Model Configuration (Enhanced Fight Detection with Improved Architecture)
# ============================================================================

model = dict(
    backbone=dict(
        type='STGCN',           # ì˜¬ë°”ë¥¸ ëª¨ë¸ íƒ€ì…
        gcn_adaptive='init',    # MMAction2 í‘œì¤€ ì„¤ì •
        gcn_with_res=True,      # ì”ì°¨ ì—°ê²° í™œì„±í™”
        tcn_type='mstcn',       # ì‹œê°„ í•©ì„±ê³± íƒ€ì…
        graph_cfg=dict(layout='coco', mode='spatial'),
        # ëª¨ë¸ ë³µì¡ë„ ì ì • ìˆ˜ì¤€ìœ¼ë¡œ ì¡°ì • (í•™ìŠµ ëŠ¥ë ¥ í–¥ìƒ)
        num_stages=8,           # 6 â†’ 8ë¡œ ì¦ê°€ (ë” ê¹Šì€ í•™ìŠµ)
        base_channels=48,       # 32 â†’ 48ë¡œ ì¦ê°€ (ë” ë§ì€ íŠ¹ì§•)
        inflate_stages=[5, 7],  # [4] â†’ [5, 7]ë¡œ í™•ì¥
        down_stages=[5, 7],     # [4] â†’ [5, 7]ë¡œ í™•ì¥
    ),
    cls_head=dict(
        type='GCNHead',
        num_classes=2,  # Fight / Non-fight
        in_channels=192,        # base_channels 48, 2ë²ˆ inflate â†’ 48*2*2 = 192 channels
        dropout=0.6,            # 0.8 â†’ 0.6ìœ¼ë¡œ ê°ì†Œ (í•™ìŠµ í™œì„±í™”)
        loss_cls=dict(
            type='CrossEntropyLoss',
            class_weight=[1.0, 1.5]         # Fight í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì™„í™” (2.0â†’1.5)
            # ì˜¤ë²„í”¼íŒ…ìœ¼ë¡œ ì¸í•œ gradient explosion ë°©ì§€
        )
    )
)

# ============================================================================
# Dataset Configuration (Enhanced Format)
# ============================================================================

# Enhanced dataset ì‚¬ìš©
dataset_type = 'PoseDataset'  # í‘œì¤€ datasetìœ¼ë¡œ ì„ì‹œ ë³€ê²½

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
data_root = '/workspace/rtmo_gcn_pipeline/rtmo_pose_track/output/UCF_Crime_test2'
ann_file_train = '/workspace/rtmo_gcn_pipeline/rtmo_pose_track/output/RWF-2000/RWF-2000_train_windows.pkl'
ann_file_val = '/workspace/rtmo_gcn_pipeline/rtmo_pose_track/output/RWF-2000/RWF-2000_val_windows.pkl'
ann_file_test = '/workspace/rtmo_gcn_pipeline/rtmo_pose_track/output/RWF-2000/RWF-2000_test_windows.pkl'

# ============================================================================
# Enhanced Pipeline Configuration with Data Augmentation
# ============================================================================

# Enhanced training pipeline (MMAction2 í‘œì¤€ transforms ì‚¬ìš©)
train_pipeline = [
    # ê¸°ë³¸ ì •ê·œí™”
    dict(type='PreNormalize2D'),
    
    # Skeleton feature ìƒì„± (bone íŠ¹ì§• ì‚¬ìš©)
    dict(type='GenSkeFeat', dataset='coco', feats=['b']),
    
    # Temporal sampling
    dict(type='UniformSampleFrames', clip_len=100),
    
    # Pose decode
    dict(type='PoseDecode'),
    
    # Final formatting
    dict(type='FormatGCNInput', num_person=4),
    dict(type='PackActionInputs')
]

# Standard validation pipeline (ì¦ê°• ì œê±°)
val_pipeline = [
    # ê¸°ë³¸ ì •ê·œí™”
    dict(type='PreNormalize2D'),
    
    # Skeleton feature ìƒì„±
    dict(type='GenSkeFeat', dataset='coco', feats=['b']),
    
    # Temporal sampling (test mode)
    dict(type='UniformSampleFrames', clip_len=100, num_clips=1, test_mode=True),
    
    # Pose decode
    dict(type='PoseDecode'),
    
    # Final formatting
    dict(type='FormatGCNInput', num_person=4),
    dict(type='PackActionInputs')
]

# Enhanced test pipeline (multiple clips for robust testing)
test_pipeline = [
    # ê¸°ë³¸ ì •ê·œí™”
    dict(type='PreNormalize2D'),
    
    # Skeleton feature ìƒì„±
    dict(type='GenSkeFeat', dataset='coco', feats=['b']),
    
    # Multiple clips for better test accuracy
    dict(type='UniformSampleFrames', clip_len=100, num_clips=10, test_mode=True),
    
    # Pose decode
    dict(type='PoseDecode'),
    
    # Final formatting
    dict(type='FormatGCNInput', num_person=4),
    dict(type='PackActionInputs')
]

# ============================================================================
# DataLoader Configuration (Optimized)
# ============================================================================

train_dataloader = dict(
    _delete_=True,  # base config dataloader ì™„ì „íˆ ë¬´ì‹œ
    batch_size=16,  # 8 â†’ 16ìœ¼ë¡œ ì¦ê°€ (ì•ˆì •ì„± í–¥ìƒ)
    num_workers=8,  # 4 â†’ 8ë¡œ ì¦ê°€ (ë” ë¹ ë¥¸ ë°ì´í„° ë¡œë”©)
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=True),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_train,
        pipeline=train_pipeline,
        test_mode=False
    )
)

val_dataloader = dict(
    _delete_=True,  # base config dataloader ì™„ì „íˆ ë¬´ì‹œ
    batch_size=16,  # 8 â†’ 16ìœ¼ë¡œ ì¦ê°€
    num_workers=8,  # 4 â†’ 8ë¡œ ì¦ê°€
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_val,
        pipeline=val_pipeline,
        test_mode=True
    )
)

test_dataloader = val_dataloader

# ============================================================================
# Training Strategy (Optimized for Gradient Stability)
# ============================================================================

# ìµœì í™”ëœ Optimizer configuration
optim_wrapper = dict(
    _delete_=True,  # base config optimizer ë¬´ì‹œ
    type='OptimWrapper',
    optimizer=dict(
        type='AdamW', 
        lr=0.0001,      # 0.0003 â†’ 0.0001ë¡œ ëŒ€í­ ê°ì†Œ (gradient explosion ë°©ì§€)
        weight_decay=0.005,     # 0.002 â†’ 0.005ë¡œ ì¦ê°€ (ì •ê·œí™” ê°•í™”)
        betas=(0.9, 0.999),      # AdamW ìµœì  ì„¤ì •
        eps=1e-8                 # ìˆ˜ì¹˜ì  ì•ˆì •ì„±
    ),
    clip_grad=dict(max_norm=1.0, norm_type=2)  # 2.0 â†’ 1.0ìœ¼ë¡œ ê°•í™” (gradient explosion ì°¨ë‹¨)
)

# ê°œì„ ëœ Learning rate scheduler
param_scheduler = [
    # ì ì ˆí•œ Warmup (3 ì—í­)
    dict(
        type='LinearLR',
        start_factor=0.01,   # 0.1 â†’ 0.01ë¡œ ê°ì†Œ (ë” ì•ˆì „í•œ ì‹œì‘)
        by_epoch=True,
        begin=0,
        end=3,               # 10 â†’ 3 ì—í­ìœ¼ë¡œ ê°ì†Œ (ì „ì²´ 15ì—í­ì— ì ì ˆ)
        convert_to_iter_based=True
    ),
    # 3 ì—í­ ì´í›„ì—ëŠ” CosineAnnealingLR ì ìš©
    dict(
        type='CosineAnnealingLR',
        by_epoch=True,
        begin=3,             # 10 â†’ 3ìœ¼ë¡œ ë³€ê²½
        T_max=12,            # 40 â†’ 12ë¡œ ì¡°ì • (15-3=12ì—í­)
        eta_min_ratio=0.001  # ë‚®ì€ ìµœì¢… í•™ìŠµë¥ 
    )
]

# Training loop configuration (ê· í˜•ì¡íŒ í•™ìŠµ ê¸°ê°„)
train_cfg = dict(
    type='EpochBasedTrainLoop',
    max_epochs=15,          # 15ì—í­ ìœ ì§€ (3ì—í­ ì›œì—… + 12ì—í­ í•™ìŠµ)
    val_begin=1,
    val_interval=1          # ë§¤ ì—í­ë§ˆë‹¤ ê²€ì¦
)

val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')

# ============================================================================
# Evaluation Configuration
# ============================================================================

# Enhanced evaluation metrics
val_evaluator = [
    dict(
        type='AccMetric',
        metric_options=dict(
            top_k_accuracy=dict(topk=(1,)),
            mean_class_accuracy=dict()
        )
    )
]

test_evaluator = val_evaluator

# ============================================================================
# Runtime Configuration (Enhanced Monitoring)
# ============================================================================

# Enhanced checkpoint and logging (í‘œì¤€ í›…ë§Œ ì‚¬ìš©)
default_hooks = dict(
    checkpoint=dict(
        type='CheckpointHook',
        interval=5,
        save_best='auto',
        max_keep_ckpts=5       # 3 â†’ 5ê°œë¡œ ì¦ê°€
    ),
    logger=dict(
        type='LoggerHook',
        interval=20,            # 50 â†’ 20ìœ¼ë¡œ ê°ì†Œ (ë” ìì£¼ ë¡œê¹…)
        ignore_last=False
    )
)

# Visualization (ê¸°ë³¸ ì„¤ì •)
vis_backends = [
    dict(type='LocalVisBackend'),
    dict(type='TensorboardVisBackend')
]
visualizer = dict(
    type='ActionVisualizer',
    vis_backends=vis_backends
)

# Model loading
load_from = '/workspace/mmaction2/checkpoints/stgcnpp_8xb16-bone-u100-80e_ntu60-xsub-keypoint-2d_20221228-cd11a691.pth'

# Work directory (ìƒˆë¡œìš´ ì‹¤í—˜ì„ ìœ„í•œ ë””ë ‰í† ë¦¬)
work_dir = '/workspace/mmaction2/work_dirs/stgcnpp-bone-ntu60_rtmo-m_RWF2000plus_conservative'

# Resume training
resume = False

# Randomness (CUDA í˜¸í™˜ì„±ì„ ìœ„í•´ deterministic=Falseë¡œ ì„¤ì •)
randomness = dict(seed=42, deterministic=False)

# Environment
env_cfg = dict(
    cudnn_benchmark=True,   # False â†’ True (ì„±ëŠ¥ í–¥ìƒ)
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='nccl'),
)

# Logging level
log_level = 'INFO'

# ============================================================================
# Enhanced Custom Hooks for Stable Training
# ============================================================================

custom_hooks = [
    # Lossê°€ ë„ˆë¬´ ë‚®ì•„ì§€ë©´ ê°•ì œ ì¢…ë£Œ (ì˜¤ë²„í”¼íŒ… ë°©ì§€)
    # ì‹¤ì œ êµ¬í˜„ì´ í•„ìš”í•˜ì§€ë§Œ ê°œë…ì ìœ¼ë¡œ ì¶”ê°€
]

# ============================================================================
# Auto Learning Rate Scaling (Optional)
# ============================================================================

# ë°°ì¹˜ í¬ê¸° ë³€ê²½ì— ë”°ë¥¸ ìë™ í•™ìŠµë¥  ì¡°ì •
auto_scale_lr = dict(
    base_batch_size=128,    # ê¸°ì¤€ ë°°ì¹˜ í¬ê¸°
    enable=True             # ìë™ ì¡°ì • í™œì„±í™”
)

# ============================================================================
# Mixed Precision Training (Optional - ë©”ëª¨ë¦¬ ì ˆì•½)
# ============================================================================

# FP16 training for memory efficiency
# optim_wrapper.update(dict(
#     type='AmpOptimWrapper',
#     loss_scale='dynamic'
# ))

# ============================================================================
# Training Command Examples
# ============================================================================

"""
Optimized STGCN++ Training Commands:

1. Basic Training (Recommended):
python tools/train.py configs/skeleton/stgcnpp/stgcnpp_enhanced_fight_detection_optimized.py

2. With distributed training:
bash tools/dist_train.sh configs/skeleton/stgcnpp/stgcnpp_enhanced_fight_detection_optimized.py 4

3. Resume training:
python tools/train.py configs/skeleton/stgcnpp/stgcnpp_enhanced_fight_detection_optimized.py --resume

4. With custom work directory:
python tools/train.py configs/skeleton/stgcnpp/stgcnpp_enhanced_fight_detection_optimized.py --work-dir work_dirs/custom_optimized

5. Testing:
python tools/test.py configs/skeleton/stgcnpp/stgcnpp_enhanced_fight_detection_optimized.py checkpoints/optimized_fight_model.pth

Key Optimizations Applied:
âœ… Gradient Clipping (max_norm=1.0) - Gradient explosion ë°©ì§€
âœ… Lower Learning Rate (0.0005) - ì•ˆì •ì ì¸ ìˆ˜ë ´
âœ… Longer Warmup (10 epochs) - ì´ˆê¸° ë¶ˆì•ˆì •ì„± ë°©ì§€
âœ… Increased Batch Size (16) - í›ˆë ¨ ì•ˆì •ì„± í–¥ìƒ
âœ… Enhanced Model Architecture - ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ (10 stages)
âœ… Regularization (Dropout 0.5) - ì˜¤ë²„í”¼íŒ… ë°©ì§€
âœ… Label Smoothing (0.1) - ì¼ë°˜í™” í–¥ìƒ
âœ… Data Augmentation - ë°ì´í„° ë‹¤ì–‘ì„± ì¦ê°€
âœ… Better Monitoring - ë” ìì£¼ ë¡œê¹… ë° ì²´í¬í¬ì¸íŠ¸

Expected Improvements:
ğŸ¯ Stable gradient norms (< 2.0)
ğŸ¯ Consistent loss decrease
ğŸ¯ Better generalization
ğŸ¯ Reduced overfitting
ğŸ¯ More stable training dynamics
"""